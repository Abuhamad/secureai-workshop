{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **HiddenTriggerBackdoor Attack** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Purpose of the Notebook:**\n",
    "\n",
    "The purpose of this notebook is to perform a backdoor attack on one of the clients in a federated learning setup. We will generate poisoned data and fine-tune the client model using both benign and poisoned samples. The aim is to create a model that classifies the poisoned data as the target label (poisoned label). Afterward, we will assess the impact of this backdoor attack on the global federated model, which aggregates results from 100 clients. We will also explore how the global model is affected as the number of clients with backdoor models increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries:\n",
    "\n",
    "* Install the Adversarial Robustness Toolbox (ART) for generating poisoned data and implementing the backdoor model.\n",
    "* We will also install other necessary libraries to support federated learning and data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mujtaba/miniconda3/envs/privatefl/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from os.path import abspath\n",
    "import random\n",
    "import copy\n",
    "\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.poisoning import HiddenTriggerBackdoor\n",
    "from art.attacks.poisoning import perturbations\n",
    "from art.attacks.poisoning.backdoor_attack import PoisoningAttackBackdoor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import relu, softmax, max_pool2d\n",
    "\n",
    "import numpy as np\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Train and Test Data:\n",
    "\n",
    "* Load the training and testing datasets that will be used for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: torch.Size([596, 1, 28, 28]), training labels shape: torch.Size([596, 10])\n",
      "Test data shape: torch.Size([94, 1, 28, 28]), test labels shape: torch.Size([94, 10])\n",
      "Additional Data features: min = -1.0, max = 1.0, std = 0.6236881017684937, mean = -0.732387363910675\n"
     ]
    }
   ],
   "source": [
    "training_data = torch.load('./FL_LDP_data/client_train_data/client_train_00.pt')\n",
    "testing_data = torch.load('./FL_LDP_data/client_test_data/client_test_00.pt')\n",
    "\n",
    "x_train = training_data['images']\n",
    "y_train = training_data['labels']\n",
    "x_test = testing_data['images']\n",
    "y_test = testing_data['labels']\n",
    "# convert the labels to one_hot_encoding\n",
    "num_classes = len(torch.unique(y_train))\n",
    "y_train = torch.nn.functional.one_hot(y_train, num_classes)\n",
    "y_test = torch.nn.functional.one_hot(y_test, num_classes)\n",
    "\n",
    "# min, max, mean, std\n",
    "min_ = x_train.min()\n",
    "max_ = x_train.max()\n",
    "std_ = torch.std(x_train)\n",
    "mean_ = torch.mean(x_train)\n",
    "\n",
    "print(f\"Train data shape: {x_train.shape}, training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}, test labels shape: {y_test.shape}\")\n",
    "print(f'Additional Data features: min = {min_}, max = {max_}, std = {std_}, mean = {mean_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Visualize the train data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,5, figsize=(15, 7))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, (image, label) in enumerate(zip(x_train[:10], y_train[:10])):\n",
    "  img = image.permute(1, 2, 0)\n",
    "  ax[i].imshow(img, cmap = \"Greys\")\n",
    "  ax[i].set_title(f\"Label: {label.argmax()}\",  fontsize=12)\n",
    "  ax[i].set_xticks([])\n",
    "  ax[i].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Visualize the test data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,5, figsize=(15, 6))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, (image, label) in enumerate(zip(x_test[:10], y_test[:10])):\n",
    "  img = image.permute(1, 2, 0)\n",
    "  ax[i].imshow(img, cmap = \"Greys\")\n",
    "  ax[i].set_title(f\"Label: {label.argmax()}\",  fontsize=12)\n",
    "  ax[i].set_xticks([])\n",
    "  ax[i].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the Model:\n",
    "\n",
    "* Build the base federated model that will be targeted in the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_fully_connected(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(mnist_fully_connected, self).__init__()\n",
    "        self.hidden1 = 600\n",
    "        self.hidden2 = 100\n",
    "        self.fc1 = nn.Linear(28 * 28, self.hidden1, bias=False)\n",
    "        self.relu_ = nn.ReLU(inplace=False)\n",
    "        self.fc2 = nn.Linear(self.hidden1, self.hidden2, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc3 = nn.Linear(self.hidden2, num_classes, bias=False)\n",
    "        \n",
    "    def forward(self,x, return_probs=True):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.relu_(self.fc1(x))\n",
    "        x = relu(self.fc2(x))\n",
    "        logits = self.fc3(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# to remove the _module in the begining of the layers.     \n",
    "def strip_prefix(state_dict, prefix=\"_module.\"):\n",
    "    \"\"\"\n",
    "    Strip a prefix from the state_dict keys.\n",
    "    Args:\n",
    "        state_dict (dict): The state_dict with the potentially prefixed keys.\n",
    "        prefix (str): The prefix to remove.\n",
    "    Returns:\n",
    "        dict: The state_dict with the prefix removed from the keys.\n",
    "    \"\"\"\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith(prefix):\n",
    "            new_state_dict[k[len(prefix):]] = v\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load and Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuray on the clean training data is :  86.07382774353027\n",
      "The accuray on the test data is :  80.85106611251831\n"
     ]
    }
   ],
   "source": [
    "model_path = './FL_LDP_data/client_model_weights/weight_user00.pth'  # Path to your saved model weights\n",
    "model = mnist_fully_connected(num_classes)\n",
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(strip_prefix(state_dict, prefix=\"_module.\"))\n",
    "\n",
    "# Check the models accuracy on the train data\n",
    "with torch.no_grad():\n",
    "    test_logits = model(x_train)\n",
    "prediction = torch.sum(torch.argmax(test_logits, axis = 1) == torch.argmax(y_train, axis = 1)) / len(y_train)\n",
    "print('The accuray on the clean training data is : ', prediction.numpy() * 100)\n",
    "\n",
    "# Check the models accuracy on the test data\n",
    "with torch.no_grad():\n",
    "    test_logits = model(x_test)\n",
    "prediction = torch.sum(torch.argmax(test_logits, axis = 1) == torch.argmax(y_test, axis = 1)) / len(y_test)\n",
    "print('The accuray on the test data is : ', prediction.numpy() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean the Data:\n",
    "\n",
    "* Filter out incorrectly classified samples to ensure only correctly classified samples are used in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76129/4004581183.py:14: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  return torch.tensor(clean_data), torch.tensor(clean_labels)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([513, 1, 28, 28]),\n",
       " torch.Size([513, 10]),\n",
       " torch.Size([76, 1, 28, 28]),\n",
       " torch.Size([76, 10]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_cleaning(model, samples, labels):\n",
    "    with torch.no_grad():\n",
    "        logits = model(samples)\n",
    "    prediction = torch.argmax(logits, axis = 1)\n",
    "\n",
    "    clean_labels = []\n",
    "    clean_data = []\n",
    "\n",
    "    for idx, pred in enumerate(prediction):\n",
    "        if pred == torch.argmax(labels[idx]):\n",
    "            clean_labels.append(labels[idx].numpy())\n",
    "            clean_data.append(samples[idx].numpy())\n",
    "\n",
    "    return torch.tensor(clean_data), torch.tensor(clean_labels)\n",
    "\n",
    "\n",
    "x_train, y_train = data_cleaning(model, x_train, y_train)\n",
    "x_test, y_test = data_cleaning(model, x_test, y_test)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuray on the clean training data is :  100.0\n",
      "The accuray on the clean testing data is :  100.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_logits = model(x_train)\n",
    "prediction = torch.sum(torch.argmax(test_logits, axis = 1) == torch.argmax(y_train, axis = 1)) / len(y_train)\n",
    "print('The accuray on the clean training data is : ', prediction.numpy() * 100)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_logits = model(x_test)\n",
    "prediction = torch.sum(torch.argmax(test_logits, axis = 1) == torch.argmax(y_test, axis = 1)) / len(y_test)\n",
    "print('The accuray on the clean testing data is : ', prediction.numpy() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the HiddenTriggerBackdoor Model:\n",
    "\n",
    "* Implement the HiddenTriggerBackdoor model to generate poisoned data and design the backdoor attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "def insert_image(\n",
    "    x: np.ndarray,\n",
    "    backdoor_path: str = \"./alert.png\",\n",
    "    channels_first: bool = False,\n",
    "    random: bool = True,\n",
    "    x_shift: int = 0,\n",
    "    y_shift: int = 0,\n",
    "    size: Optional[Tuple[int, int]] = None,\n",
    "    mode: str = \"L\",\n",
    "    blend=0.8,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Augments a matrix by setting a checkerboard-like pattern of values some `distance` away from the bottom-right\n",
    "    edge to 1. Works for single images or a batch of images.\n",
    "\n",
    "    :param x: A single image or batch of images of shape NHWC, NCHW, or HWC. Input is in range [0,1].\n",
    "    :param backdoor_path: The path to the image to insert as a trigger.\n",
    "    :param channels_first: Whether the channels axis is in the first or last dimension\n",
    "    :param random: Whether or not the image should be randomly placed somewhere on the image.\n",
    "    :param x_shift: Number of pixels from the left to shift the trigger (when not using random placement).\n",
    "    :param y_shift: Number of pixels from the right to shift the trigger (when not using random placement).\n",
    "    :param size: The size the trigger image should be (height, width). Default `None` if no resizing necessary.\n",
    "    :param mode: The mode the image should be read in. See PIL documentation\n",
    "                 (https://pillow.readthedocs.io/en/stable/handbook/concepts.html#concept-modes).\n",
    "    :param blend: The blending factor\n",
    "    :return: Backdoored image.\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "\n",
    "    n_dim = len(x.shape)\n",
    "    if n_dim == 4:\n",
    "        return np.array(\n",
    "            [\n",
    "                insert_image(single_img, backdoor_path, channels_first, random, x_shift, y_shift, size, mode, blend)\n",
    "                for single_img in x\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if n_dim != 3:\n",
    "        raise ValueError(f\"Invalid array shape {x.shape}\")\n",
    "\n",
    "    original_dtype = x.dtype\n",
    "    data = np.copy(x)\n",
    "    if channels_first:\n",
    "        data = np.transpose(data, (1, 2, 0))\n",
    "\n",
    "    height, width, num_channels = data.shape\n",
    "\n",
    "    no_color = num_channels == 1\n",
    "    orig_img = Image.new(\"RGBA\", (width, height), 0)  # height and width are swapped for PIL\n",
    "    backdoored_img = Image.new(\"RGBA\", (width, height), 0)  # height and width are swapped for PIL\n",
    "\n",
    "    if no_color:\n",
    "        backdoored_input = Image.fromarray(((data + 1) * 127.5).astype(np.uint8).squeeze(axis=2), mode=mode)\n",
    "    else:\n",
    "        backdoored_input = Image.fromarray(((data + 1) * 127.5).astype(np.uint8), mode=mode)\n",
    "\n",
    "    orig_img.paste(backdoored_input)\n",
    "\n",
    "    trigger = Image.open(backdoor_path).convert(\"RGBA\")\n",
    "    if size is not None:\n",
    "        trigger = trigger.resize((size[1], size[0]))  # height and width are swapped for PIL\n",
    "\n",
    "    backdoor_width, backdoor_height = trigger.size  # height and width are swapped for PIL\n",
    "\n",
    "    if backdoor_width > width or backdoor_height > height:\n",
    "        raise ValueError(\"Backdoor does not fit inside original image\")\n",
    "\n",
    "    if random:\n",
    "        x_shift = np.random.randint(width - backdoor_width + 1)\n",
    "        y_shift = np.random.randint(height - backdoor_height + 1)\n",
    "\n",
    "    backdoored_img.paste(trigger, (x_shift, y_shift), mask=trigger)\n",
    "    composite = Image.alpha_composite(orig_img, backdoored_img)\n",
    "    backdoored_img = Image.blend(orig_img, composite, blend)\n",
    "    backdoored_img = backdoored_img.convert(mode)\n",
    "\n",
    "    res = (np.asarray(backdoored_img) / 127.5 ) - 1\n",
    "\n",
    "    if no_color:\n",
    "        res = np.expand_dims(res, 2)\n",
    "\n",
    "    if channels_first:\n",
    "        res = np.transpose(res, (2, 0, 1))\n",
    "\n",
    "    return res.astype(original_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Generate the poisoned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hidden Trigger:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0 | i:     0 |                         LR: 0.00100 |                         Loss Val: 20212.049 | Loss Avg: 20212.049\n",
      "Batch: 0 | i:   100 |                         LR: 0.00100 |                         Loss Val: 1309.823 | Loss Avg: 3939.996\n",
      "Batch: 0 | i:   200 |                         LR: 0.00100 |                         Loss Val: 852.002 | Loss Avg: 2488.404\n",
      "Batch: 0 | i:   300 |                         LR: 0.00100 |                         Loss Val: 718.883 | Loss Avg: 1918.942\n",
      "Batch: 0 | i:   400 |                         LR: 0.00100 |                         Loss Val: 656.086 | Loss Avg: 1611.016\n",
      "Batch: 0 | i:   500 |                         LR: 0.00100 |                         Loss Val: 620.731 | Loss Avg: 1416.554\n",
      "Batch: 0 | i:   600 |                         LR: 0.00100 |                         Loss Val: 598.311 | Loss Avg: 1282.127\n",
      "Batch: 0 | i:   700 |                         LR: 0.00100 |                         Loss Val: 583.469 | Loss Avg: 1183.444\n",
      "Batch: 0 | i:   800 |                         LR: 0.00100 |                         Loss Val: 572.806 | Loss Avg: 1107.830\n",
      "Batch: 0 | i:   900 |                         LR: 0.00100 |                         Loss Val: 565.234 | Loss Avg: 1048.005\n",
      "Batch: 0 | i:  1000 |                         LR: 0.00100 |                         Loss Val: 559.299 | Loss Avg: 999.466\n",
      "Batch: 0 | i:  1100 |                         LR: 0.00100 |                         Loss Val: 554.691 | Loss Avg: 959.265\n",
      "Batch: 0 | i:  1200 |                         LR: 0.00100 |                         Loss Val: 551.117 | Loss Avg: 925.420\n",
      "Batch: 0 | i:  1300 |                         LR: 0.00100 |                         Loss Val: 548.184 | Loss Avg: 896.532\n",
      "Batch: 0 | i:  1400 |                         LR: 0.00100 |                         Loss Val: 545.889 | Loss Avg: 871.581\n",
      "Batch: 0 | i:  1500 |                         LR: 0.00100 |                         Loss Val: 543.977 | Loss Avg: 849.818\n",
      "Batch: 0 | i:  1600 |                         LR: 0.00100 |                         Loss Val: 541.846 | Loss Avg: 830.653\n",
      "Batch: 0 | i:  1700 |                         LR: 0.00100 |                         Loss Val: 539.836 | Loss Avg: 813.613\n",
      "Batch: 0 | i:  1800 |                         LR: 0.00100 |                         Loss Val: 538.146 | Loss Avg: 798.364\n",
      "Batch: 0 | i:  1900 |                         LR: 0.00100 |                         Loss Val: 536.680 | Loss Avg: 784.635\n",
      "Batch: 0 | i:  2000 |                         LR: 0.00095 |                         Loss Val: 535.190 | Loss Avg: 772.204\n",
      "Batch: 0 | i:  2100 |                         LR: 0.00095 |                         Loss Val: 534.024 | Loss Avg: 760.895\n",
      "Batch: 0 | i:  2200 |                         LR: 0.00095 |                         Loss Val: 533.107 | Loss Avg: 750.566\n",
      "Batch: 0 | i:  2300 |                         LR: 0.00095 |                         Loss Val: 532.234 | Loss Avg: 741.095\n",
      "Batch: 0 | i:  2400 |                         LR: 0.00095 |                         Loss Val: 531.468 | Loss Avg: 732.380\n",
      "Batch: 0 | i:  2500 |                         LR: 0.00095 |                         Loss Val: 530.736 | Loss Avg: 724.332\n",
      "Batch: 0 | i:  2600 |                         LR: 0.00095 |                         Loss Val: 530.130 | Loss Avg: 716.877\n",
      "Batch: 0 | i:  2700 |                         LR: 0.00095 |                         Loss Val: 529.608 | Loss Avg: 709.954\n",
      "Batch: 0 | i:  2800 |                         LR: 0.00095 |                         Loss Val: 529.153 | Loss Avg: 703.507\n",
      "Batch: 0 | i:  2900 |                         LR: 0.00095 |                         Loss Val: 528.704 | Loss Avg: 697.489\n",
      "Batch: 0 | i:  3000 |                         LR: 0.00095 |                         Loss Val: 528.154 | Loss Avg: 691.856\n",
      "Batch: 0 | i:  3100 |                         LR: 0.00095 |                         Loss Val: 527.537 | Loss Avg: 686.566\n",
      "Batch: 0 | i:  3200 |                         LR: 0.00095 |                         Loss Val: 527.011 | Loss Avg: 681.589\n",
      "Batch: 0 | i:  3300 |                         LR: 0.00095 |                         Loss Val: 526.563 | Loss Avg: 676.900\n",
      "Batch: 0 | i:  3400 |                         LR: 0.00095 |                         Loss Val: 526.220 | Loss Avg: 672.474\n",
      "Batch: 0 | i:  3500 |                         LR: 0.00095 |                         Loss Val: 525.848 | Loss Avg: 668.291\n",
      "Batch: 0 | i:  3600 |                         LR: 0.00095 |                         Loss Val: 525.557 | Loss Avg: 664.331\n",
      "Batch: 0 | i:  3700 |                         LR: 0.00095 |                         Loss Val: 525.223 | Loss Avg: 660.577\n",
      "Batch: 0 | i:  3800 |                         LR: 0.00095 |                         Loss Val: 524.743 | Loss Avg: 657.011\n",
      "Batch: 0 | i:  3900 |                         LR: 0.00095 |                         Loss Val: 524.211 | Loss Avg: 653.614\n",
      "Batch: 0 | i:  4000 |                         LR: 0.00090 |                         Loss Val: 523.810 | Loss Avg: 650.374\n",
      "Batch: 0 | i:  4100 |                         LR: 0.00090 |                         Loss Val: 523.432 | Loss Avg: 647.283\n",
      "Batch: 0 | i:  4200 |                         LR: 0.00090 |                         Loss Val: 523.137 | Loss Avg: 644.331\n",
      "Batch: 0 | i:  4300 |                         LR: 0.00090 |                         Loss Val: 522.837 | Loss Avg: 641.510\n",
      "Batch: 0 | i:  4400 |                         LR: 0.00090 |                         Loss Val: 522.630 | Loss Avg: 638.811\n",
      "Batch: 0 | i:  4500 |                         LR: 0.00090 |                         Loss Val: 522.399 | Loss Avg: 636.227\n",
      "Batch: 0 | i:  4600 |                         LR: 0.00090 |                         Loss Val: 522.197 | Loss Avg: 633.750\n",
      "Batch: 0 | i:  4700 |                         LR: 0.00090 |                         Loss Val: 522.008 | Loss Avg: 631.375\n",
      "Batch: 0 | i:  4800 |                         LR: 0.00090 |                         Loss Val: 521.801 | Loss Avg: 629.094\n",
      "Batch: 0 | i:  4900 |                         LR: 0.00090 |                         Loss Val: 521.655 | Loss Avg: 626.904\n",
      "Batch: 0 | i:  5000 |                         LR: 0.00090 |                         Loss Val: 521.508 | Loss Avg: 624.798\n",
      "Batch: 0 | i:  5100 |                         LR: 0.00090 |                         Loss Val: 521.353 | Loss Avg: 622.771\n",
      "Batch: 0 | i:  5200 |                         LR: 0.00090 |                         Loss Val: 521.218 | Loss Avg: 620.820\n",
      "Batch: 0 | i:  5300 |                         LR: 0.00090 |                         Loss Val: 521.079 | Loss Avg: 618.939\n",
      "Batch: 0 | i:  5400 |                         LR: 0.00090 |                         Loss Val: 521.009 | Loss Avg: 617.127\n",
      "Batch: 0 | i:  5500 |                         LR: 0.00090 |                         Loss Val: 520.757 | Loss Avg: 615.377\n",
      "Batch: 0 | i:  5600 |                         LR: 0.00090 |                         Loss Val: 520.608 | Loss Avg: 613.687\n",
      "Batch: 0 | i:  5700 |                         LR: 0.00090 |                         Loss Val: 520.403 | Loss Avg: 612.052\n",
      "Batch: 0 | i:  5800 |                         LR: 0.00090 |                         Loss Val: 520.250 | Loss Avg: 610.471\n",
      "Batch: 0 | i:  5900 |                         LR: 0.00090 |                         Loss Val: 520.120 | Loss Avg: 608.941\n",
      "Batch: 0 | i:  6000 |                         LR: 0.00086 |                         Loss Val: 519.963 | Loss Avg: 607.460\n",
      "Batch: 0 | i:  6100 |                         LR: 0.00086 |                         Loss Val: 519.874 | Loss Avg: 606.025\n",
      "Batch: 0 | i:  6200 |                         LR: 0.00086 |                         Loss Val: 519.756 | Loss Avg: 604.635\n",
      "Batch: 0 | i:  6300 |                         LR: 0.00086 |                         Loss Val: 519.676 | Loss Avg: 603.287\n",
      "Batch: 0 | i:  6400 |                         LR: 0.00086 |                         Loss Val: 519.602 | Loss Avg: 601.980\n",
      "Batch: 0 | i:  6500 |                         LR: 0.00086 |                         Loss Val: 519.525 | Loss Avg: 600.712\n",
      "Batch: 0 | i:  6600 |                         LR: 0.00086 |                         Loss Val: 519.463 | Loss Avg: 599.482\n",
      "Batch: 0 | i:  6700 |                         LR: 0.00086 |                         Loss Val: 519.364 | Loss Avg: 598.287\n",
      "Batch: 0 | i:  6800 |                         LR: 0.00086 |                         Loss Val: 519.192 | Loss Avg: 597.125\n",
      "Batch: 0 | i:  6900 |                         LR: 0.00086 |                         Loss Val: 519.052 | Loss Avg: 595.995\n",
      "Batch: 0 | i:  7000 |                         LR: 0.00086 |                         Loss Val: 518.948 | Loss Avg: 594.895\n",
      "Batch: 0 | i:  7100 |                         LR: 0.00086 |                         Loss Val: 518.799 | Loss Avg: 593.824\n",
      "Batch: 0 | i:  7200 |                         LR: 0.00086 |                         Loss Val: 518.651 | Loss Avg: 592.781\n",
      "Batch: 0 | i:  7300 |                         LR: 0.00086 |                         Loss Val: 518.500 | Loss Avg: 591.765\n",
      "Batch: 0 | i:  7400 |                         LR: 0.00086 |                         Loss Val: 518.357 | Loss Avg: 590.773\n",
      "Batch: 0 | i:  7500 |                         LR: 0.00086 |                         Loss Val: 518.265 | Loss Avg: 589.807\n",
      "Batch: 0 | i:  7600 |                         LR: 0.00086 |                         Loss Val: 518.139 | Loss Avg: 588.865\n",
      "Batch: 0 | i:  7700 |                         LR: 0.00086 |                         Loss Val: 518.024 | Loss Avg: 587.946\n",
      "Batch: 0 | i:  7800 |                         LR: 0.00086 |                         Loss Val: 517.934 | Loss Avg: 587.050\n",
      "Batch: 0 | i:  7900 |                         LR: 0.00086 |                         Loss Val: 517.869 | Loss Avg: 586.175\n",
      "Batch: 0 | i:  8000 |                         LR: 0.00081 |                         Loss Val: 517.802 | Loss Avg: 585.321\n",
      "Batch: 0 | i:  8100 |                         LR: 0.00081 |                         Loss Val: 517.751 | Loss Avg: 584.487\n",
      "Batch: 0 | i:  8200 |                         LR: 0.00081 |                         Loss Val: 517.682 | Loss Avg: 583.673\n",
      "Batch: 0 | i:  8300 |                         LR: 0.00081 |                         Loss Val: 517.583 | Loss Avg: 582.877\n",
      "Batch: 0 | i:  8400 |                         LR: 0.00081 |                         Loss Val: 517.533 | Loss Avg: 582.100\n",
      "Batch: 0 | i:  8500 |                         LR: 0.00081 |                         Loss Val: 517.383 | Loss Avg: 581.340\n",
      "Batch: 0 | i:  8600 |                         LR: 0.00081 |                         Loss Val: 517.119 | Loss Avg: 580.595\n",
      "Batch: 0 | i:  8700 |                         LR: 0.00081 |                         Loss Val: 516.855 | Loss Avg: 579.864\n",
      "Batch: 0 | i:  8800 |                         LR: 0.00081 |                         Loss Val: 516.612 | Loss Avg: 579.146\n",
      "Batch: 0 | i:  8900 |                         LR: 0.00081 |                         Loss Val: 516.425 | Loss Avg: 578.443\n",
      "Batch: 0 | i:  9000 |                         LR: 0.00081 |                         Loss Val: 516.229 | Loss Avg: 577.753\n",
      "Batch: 0 | i:  9100 |                         LR: 0.00081 |                         Loss Val: 516.030 | Loss Avg: 577.076\n",
      "Batch: 0 | i:  9200 |                         LR: 0.00081 |                         Loss Val: 515.848 | Loss Avg: 576.411\n",
      "Batch: 0 | i:  9300 |                         LR: 0.00081 |                         Loss Val: 515.745 | Loss Avg: 575.760\n",
      "Batch: 0 | i:  9400 |                         LR: 0.00081 |                         Loss Val: 515.561 | Loss Avg: 575.120\n",
      "Batch: 0 | i:  9500 |                         LR: 0.00081 |                         Loss Val: 515.444 | Loss Avg: 574.492\n",
      "Batch: 0 | i:  9600 |                         LR: 0.00081 |                         Loss Val: 515.302 | Loss Avg: 573.877\n",
      "Batch: 0 | i:  9700 |                         LR: 0.00081 |                         Loss Val: 515.217 | Loss Avg: 573.272\n",
      "Batch: 0 | i:  9800 |                         LR: 0.00081 |                         Loss Val: 515.105 | Loss Avg: 572.679\n",
      "Batch: 0 | i:  9900 |                         LR: 0.00081 |                         Loss Val: 515.010 | Loss Avg: 572.097\n",
      "Batch: 0 | i: 10000 |                         LR: 0.00077 |                         Loss Val: 514.939 | Loss Avg: 571.526\n",
      "Batch: 0 | i: 10100 |                         LR: 0.00077 |                         Loss Val: 514.831 | Loss Avg: 570.965\n",
      "Batch: 0 | i: 10200 |                         LR: 0.00077 |                         Loss Val: 514.776 | Loss Avg: 570.414\n",
      "Batch: 0 | i: 10300 |                         LR: 0.00077 |                         Loss Val: 514.719 | Loss Avg: 569.874\n",
      "Batch: 0 | i: 10400 |                         LR: 0.00077 |                         Loss Val: 514.663 | Loss Avg: 569.343\n",
      "Batch: 0 | i: 10500 |                         LR: 0.00077 |                         Loss Val: 514.614 | Loss Avg: 568.822\n",
      "Batch: 0 | i: 10600 |                         LR: 0.00077 |                         Loss Val: 514.626 | Loss Avg: 568.311\n",
      "Batch: 0 | i: 10700 |                         LR: 0.00077 |                         Loss Val: 514.522 | Loss Avg: 567.809\n",
      "Batch: 0 | i: 10800 |                         LR: 0.00077 |                         Loss Val: 514.485 | Loss Avg: 567.315\n",
      "Batch: 0 | i: 10900 |                         LR: 0.00077 |                         Loss Val: 514.454 | Loss Avg: 566.830\n",
      "Batch: 0 | i: 11000 |                         LR: 0.00077 |                         Loss Val: 514.389 | Loss Avg: 566.354\n",
      "Batch: 0 | i: 11100 |                         LR: 0.00077 |                         Loss Val: 514.372 | Loss Avg: 565.886\n",
      "Batch: 0 | i: 11200 |                         LR: 0.00077 |                         Loss Val: 514.363 | Loss Avg: 565.426\n",
      "Batch: 0 | i: 11300 |                         LR: 0.00077 |                         Loss Val: 514.337 | Loss Avg: 564.974\n",
      "Batch: 0 | i: 11400 |                         LR: 0.00077 |                         Loss Val: 514.296 | Loss Avg: 564.530\n",
      "Batch: 0 | i: 11500 |                         LR: 0.00077 |                         Loss Val: 514.224 | Loss Avg: 564.093\n",
      "Batch: 0 | i: 11600 |                         LR: 0.00077 |                         Loss Val: 514.236 | Loss Avg: 563.663\n",
      "Batch: 0 | i: 11700 |                         LR: 0.00077 |                         Loss Val: 514.196 | Loss Avg: 563.240\n",
      "Batch: 0 | i: 11800 |                         LR: 0.00077 |                         Loss Val: 514.181 | Loss Avg: 562.825\n",
      "Batch: 0 | i: 11900 |                         LR: 0.00077 |                         Loss Val: 514.134 | Loss Avg: 562.416\n",
      "Batch: 0 | i: 12000 |                         LR: 0.00074 |                         Loss Val: 514.120 | Loss Avg: 562.014\n",
      "Batch: 0 | i: 12100 |                         LR: 0.00074 |                         Loss Val: 514.122 | Loss Avg: 561.618\n",
      "Batch: 0 | i: 12200 |                         LR: 0.00074 |                         Loss Val: 514.102 | Loss Avg: 561.228\n",
      "Batch: 0 | i: 12300 |                         LR: 0.00074 |                         Loss Val: 514.057 | Loss Avg: 560.844\n",
      "Batch: 0 | i: 12400 |                         LR: 0.00074 |                         Loss Val: 514.048 | Loss Avg: 560.467\n",
      "Batch: 0 | i: 12500 |                         LR: 0.00074 |                         Loss Val: 513.995 | Loss Avg: 560.095\n",
      "Batch: 0 | i: 12600 |                         LR: 0.00074 |                         Loss Val: 513.958 | Loss Avg: 559.729\n",
      "Batch: 0 | i: 12700 |                         LR: 0.00074 |                         Loss Val: 513.940 | Loss Avg: 559.369\n",
      "Batch: 0 | i: 12800 |                         LR: 0.00074 |                         Loss Val: 513.922 | Loss Avg: 559.014\n",
      "Batch: 0 | i: 12900 |                         LR: 0.00074 |                         Loss Val: 513.904 | Loss Avg: 558.665\n",
      "Batch: 0 | i: 13000 |                         LR: 0.00074 |                         Loss Val: 513.895 | Loss Avg: 558.321\n",
      "Batch: 0 | i: 13100 |                         LR: 0.00074 |                         Loss Val: 513.877 | Loss Avg: 557.981\n",
      "Batch: 0 | i: 13200 |                         LR: 0.00074 |                         Loss Val: 513.856 | Loss Avg: 557.647\n",
      "Batch: 0 | i: 13300 |                         LR: 0.00074 |                         Loss Val: 513.768 | Loss Avg: 557.317\n",
      "Batch: 0 | i: 13400 |                         LR: 0.00074 |                         Loss Val: 513.747 | Loss Avg: 556.992\n",
      "Batch: 0 | i: 13500 |                         LR: 0.00074 |                         Loss Val: 513.707 | Loss Avg: 556.672\n",
      "Batch: 0 | i: 13600 |                         LR: 0.00074 |                         Loss Val: 513.657 | Loss Avg: 556.356\n",
      "Batch: 0 | i: 13700 |                         LR: 0.00074 |                         Loss Val: 513.646 | Loss Avg: 556.044\n",
      "Batch: 0 | i: 13800 |                         LR: 0.00074 |                         Loss Val: 513.616 | Loss Avg: 555.737\n",
      "Batch: 0 | i: 13900 |                         LR: 0.00074 |                         Loss Val: 513.570 | Loss Avg: 555.434\n",
      "Batch: 0 | i: 14000 |                         LR: 0.00070 |                         Loss Val: 513.554 | Loss Avg: 555.135\n",
      "Batch: 0 | i: 14100 |                         LR: 0.00070 |                         Loss Val: 513.491 | Loss Avg: 554.840\n",
      "Batch: 0 | i: 14200 |                         LR: 0.00070 |                         Loss Val: 513.453 | Loss Avg: 554.549\n",
      "Batch: 0 | i: 14300 |                         LR: 0.00070 |                         Loss Val: 513.407 | Loss Avg: 554.261\n",
      "Batch: 0 | i: 14400 |                         LR: 0.00070 |                         Loss Val: 513.362 | Loss Avg: 553.977\n",
      "Batch: 0 | i: 14500 |                         LR: 0.00070 |                         Loss Val: 513.325 | Loss Avg: 553.697\n",
      "Batch: 0 | i: 14600 |                         LR: 0.00070 |                         Loss Val: 513.286 | Loss Avg: 553.421\n",
      "Batch: 0 | i: 14700 |                         LR: 0.00070 |                         Loss Val: 513.246 | Loss Avg: 553.148\n",
      "Batch: 0 | i: 14800 |                         LR: 0.00070 |                         Loss Val: 513.232 | Loss Avg: 552.878\n",
      "Batch: 0 | i: 14900 |                         LR: 0.00070 |                         Loss Val: 513.187 | Loss Avg: 552.612\n",
      "Batch: 0 | i: 15000 |                         LR: 0.00070 |                         Loss Val: 513.140 | Loss Avg: 552.349\n",
      "Batch: 0 | i: 15100 |                         LR: 0.00070 |                         Loss Val: 513.115 | Loss Avg: 552.089\n",
      "Batch: 0 | i: 15200 |                         LR: 0.00070 |                         Loss Val: 513.108 | Loss Avg: 551.832\n",
      "Batch: 0 | i: 15300 |                         LR: 0.00070 |                         Loss Val: 513.052 | Loss Avg: 551.579\n",
      "Batch: 0 | i: 15400 |                         LR: 0.00070 |                         Loss Val: 512.995 | Loss Avg: 551.329\n",
      "Batch: 0 | i: 15500 |                         LR: 0.00070 |                         Loss Val: 513.016 | Loss Avg: 551.082\n",
      "Batch: 0 | i: 15600 |                         LR: 0.00070 |                         Loss Val: 512.957 | Loss Avg: 550.837\n",
      "Batch: 0 | i: 15700 |                         LR: 0.00070 |                         Loss Val: 512.922 | Loss Avg: 550.596\n",
      "Batch: 0 | i: 15800 |                         LR: 0.00070 |                         Loss Val: 512.910 | Loss Avg: 550.358\n",
      "Batch: 0 | i: 15900 |                         LR: 0.00070 |                         Loss Val: 512.897 | Loss Avg: 550.122\n",
      "Batch: 0 | i: 16000 |                         LR: 0.00066 |                         Loss Val: 512.866 | Loss Avg: 549.889\n",
      "Batch: 0 | i: 16100 |                         LR: 0.00066 |                         Loss Val: 512.830 | Loss Avg: 549.659\n",
      "Batch: 0 | i: 16200 |                         LR: 0.00066 |                         Loss Val: 512.824 | Loss Avg: 549.432\n",
      "Batch: 0 | i: 16300 |                         LR: 0.00066 |                         Loss Val: 512.789 | Loss Avg: 549.207\n",
      "Batch: 0 | i: 16400 |                         LR: 0.00066 |                         Loss Val: 512.772 | Loss Avg: 548.985\n",
      "Batch: 0 | i: 16500 |                         LR: 0.00066 |                         Loss Val: 512.764 | Loss Avg: 548.766\n",
      "Batch: 0 | i: 16600 |                         LR: 0.00066 |                         Loss Val: 512.744 | Loss Avg: 548.549\n",
      "Batch: 0 | i: 16700 |                         LR: 0.00066 |                         Loss Val: 512.733 | Loss Avg: 548.334\n",
      "Batch: 0 | i: 16800 |                         LR: 0.00066 |                         Loss Val: 512.709 | Loss Avg: 548.122\n",
      "Batch: 0 | i: 16900 |                         LR: 0.00066 |                         Loss Val: 512.704 | Loss Avg: 547.913\n",
      "Batch: 0 | i: 17000 |                         LR: 0.00066 |                         Loss Val: 512.688 | Loss Avg: 547.706\n",
      "Batch: 0 | i: 17100 |                         LR: 0.00066 |                         Loss Val: 512.708 | Loss Avg: 547.501\n",
      "Batch: 0 | i: 17200 |                         LR: 0.00066 |                         Loss Val: 512.658 | Loss Avg: 547.299\n",
      "Batch: 0 | i: 17300 |                         LR: 0.00066 |                         Loss Val: 512.653 | Loss Avg: 547.098\n",
      "Batch: 0 | i: 17400 |                         LR: 0.00066 |                         Loss Val: 512.634 | Loss Avg: 546.900\n",
      "Batch: 0 | i: 17500 |                         LR: 0.00066 |                         Loss Val: 512.622 | Loss Avg: 546.705\n",
      "Batch: 0 | i: 17600 |                         LR: 0.00066 |                         Loss Val: 512.585 | Loss Avg: 546.511\n",
      "Batch: 0 | i: 17700 |                         LR: 0.00066 |                         Loss Val: 512.581 | Loss Avg: 546.319\n",
      "Batch: 0 | i: 17800 |                         LR: 0.00066 |                         Loss Val: 512.595 | Loss Avg: 546.130\n",
      "Batch: 0 | i: 17900 |                         LR: 0.00066 |                         Loss Val: 512.561 | Loss Avg: 545.942\n",
      "Batch: 0 | i: 18000 |                         LR: 0.00063 |                         Loss Val: 512.526 | Loss Avg: 545.757\n",
      "Batch: 0 | i: 18100 |                         LR: 0.00063 |                         Loss Val: 512.501 | Loss Avg: 545.573\n",
      "Batch: 0 | i: 18200 |                         LR: 0.00063 |                         Loss Val: 512.471 | Loss Avg: 545.391\n",
      "Batch: 0 | i: 18300 |                         LR: 0.00063 |                         Loss Val: 512.455 | Loss Avg: 545.211\n",
      "Batch: 0 | i: 18400 |                         LR: 0.00063 |                         Loss Val: 512.428 | Loss Avg: 545.033\n",
      "Batch: 0 | i: 18500 |                         LR: 0.00063 |                         Loss Val: 512.418 | Loss Avg: 544.857\n",
      "Batch: 0 | i: 18600 |                         LR: 0.00063 |                         Loss Val: 512.385 | Loss Avg: 544.682\n",
      "Batch: 0 | i: 18700 |                         LR: 0.00063 |                         Loss Val: 512.385 | Loss Avg: 544.510\n",
      "Batch: 0 | i: 18800 |                         LR: 0.00063 |                         Loss Val: 512.346 | Loss Avg: 544.339\n",
      "Batch: 0 | i: 18900 |                         LR: 0.00063 |                         Loss Val: 512.356 | Loss Avg: 544.169\n",
      "Batch: 0 | i: 19000 |                         LR: 0.00063 |                         Loss Val: 512.340 | Loss Avg: 544.002\n",
      "Batch: 0 | i: 19100 |                         LR: 0.00063 |                         Loss Val: 512.323 | Loss Avg: 543.836\n",
      "Batch: 0 | i: 19200 |                         LR: 0.00063 |                         Loss Val: 512.288 | Loss Avg: 543.672\n",
      "Batch: 0 | i: 19300 |                         LR: 0.00063 |                         Loss Val: 512.270 | Loss Avg: 543.509\n",
      "Batch: 0 | i: 19400 |                         LR: 0.00063 |                         Loss Val: 512.263 | Loss Avg: 543.348\n",
      "Batch: 0 | i: 19500 |                         LR: 0.00063 |                         Loss Val: 512.242 | Loss Avg: 543.189\n",
      "Batch: 0 | i: 19600 |                         LR: 0.00063 |                         Loss Val: 512.208 | Loss Avg: 543.031\n",
      "Batch: 0 | i: 19700 |                         LR: 0.00063 |                         Loss Val: 512.178 | Loss Avg: 542.874\n",
      "Batch: 0 | i: 19800 |                         LR: 0.00063 |                         Loss Val: 512.168 | Loss Avg: 542.719\n",
      "Batch: 0 | i: 19900 |                         LR: 0.00063 |                         Loss Val: 512.155 | Loss Avg: 542.566\n",
      "Batch: 0 | i: 20000 |                         LR: 0.00060 |                         Loss Val: 512.135 | Loss Avg: 542.414\n",
      "Batch: 0 | i: 20100 |                         LR: 0.00060 |                         Loss Val: 512.125 | Loss Avg: 542.263\n",
      "Batch: 0 | i: 20200 |                         LR: 0.00060 |                         Loss Val: 512.090 | Loss Avg: 542.114\n",
      "Batch: 0 | i: 20300 |                         LR: 0.00060 |                         Loss Val: 512.090 | Loss Avg: 541.966\n",
      "Batch: 0 | i: 20400 |                         LR: 0.00060 |                         Loss Val: 512.079 | Loss Avg: 541.819\n",
      "Batch: 0 | i: 20500 |                         LR: 0.00060 |                         Loss Val: 512.076 | Loss Avg: 541.674\n",
      "Batch: 0 | i: 20600 |                         LR: 0.00060 |                         Loss Val: 512.046 | Loss Avg: 541.530\n",
      "Batch: 0 | i: 20700 |                         LR: 0.00060 |                         Loss Val: 512.038 | Loss Avg: 541.388\n",
      "Batch: 0 | i: 20800 |                         LR: 0.00060 |                         Loss Val: 512.010 | Loss Avg: 541.247\n",
      "Batch: 0 | i: 20900 |                         LR: 0.00060 |                         Loss Val: 512.008 | Loss Avg: 541.107\n",
      "Batch: 0 | i: 21000 |                         LR: 0.00060 |                         Loss Val: 512.010 | Loss Avg: 540.968\n",
      "Batch: 0 | i: 21100 |                         LR: 0.00060 |                         Loss Val: 512.005 | Loss Avg: 540.831\n",
      "Batch: 0 | i: 21200 |                         LR: 0.00060 |                         Loss Val: 511.992 | Loss Avg: 540.695\n",
      "Batch: 0 | i: 21300 |                         LR: 0.00060 |                         Loss Val: 511.973 | Loss Avg: 540.560\n",
      "Batch: 0 | i: 21400 |                         LR: 0.00060 |                         Loss Val: 511.963 | Loss Avg: 540.427\n",
      "Batch: 0 | i: 21500 |                         LR: 0.00060 |                         Loss Val: 511.968 | Loss Avg: 540.294\n",
      "Batch: 0 | i: 21600 |                         LR: 0.00060 |                         Loss Val: 511.944 | Loss Avg: 540.163\n",
      "Batch: 0 | i: 21700 |                         LR: 0.00060 |                         Loss Val: 511.953 | Loss Avg: 540.033\n",
      "Batch: 0 | i: 21800 |                         LR: 0.00060 |                         Loss Val: 511.937 | Loss Avg: 539.904\n",
      "Batch: 0 | i: 21900 |                         LR: 0.00060 |                         Loss Val: 511.913 | Loss Avg: 539.776\n",
      "Batch: 0 | i: 22000 |                         LR: 0.00057 |                         Loss Val: 511.956 | Loss Avg: 539.650\n",
      "Batch: 0 | i: 22100 |                         LR: 0.00057 |                         Loss Val: 511.922 | Loss Avg: 539.524\n",
      "Batch: 0 | i: 22200 |                         LR: 0.00057 |                         Loss Val: 511.918 | Loss Avg: 539.400\n",
      "Batch: 0 | i: 22300 |                         LR: 0.00057 |                         Loss Val: 511.907 | Loss Avg: 539.277\n",
      "Batch: 0 | i: 22400 |                         LR: 0.00057 |                         Loss Val: 511.909 | Loss Avg: 539.155\n",
      "Batch: 0 | i: 22500 |                         LR: 0.00057 |                         Loss Val: 511.880 | Loss Avg: 539.033\n",
      "Batch: 0 | i: 22600 |                         LR: 0.00057 |                         Loss Val: 511.892 | Loss Avg: 538.913\n",
      "Batch: 0 | i: 22700 |                         LR: 0.00057 |                         Loss Val: 511.916 | Loss Avg: 538.794\n",
      "Batch: 0 | i: 22800 |                         LR: 0.00057 |                         Loss Val: 511.886 | Loss Avg: 538.676\n",
      "Batch: 0 | i: 22900 |                         LR: 0.00057 |                         Loss Val: 511.898 | Loss Avg: 538.559\n",
      "Batch: 0 | i: 23000 |                         LR: 0.00057 |                         Loss Val: 511.867 | Loss Avg: 538.443\n",
      "Batch: 0 | i: 23100 |                         LR: 0.00057 |                         Loss Val: 511.878 | Loss Avg: 538.328\n",
      "Batch: 0 | i: 23200 |                         LR: 0.00057 |                         Loss Val: 511.875 | Loss Avg: 538.214\n",
      "Batch: 0 | i: 23300 |                         LR: 0.00057 |                         Loss Val: 511.851 | Loss Avg: 538.101\n",
      "Batch: 0 | i: 23400 |                         LR: 0.00057 |                         Loss Val: 511.845 | Loss Avg: 537.989\n",
      "Batch: 0 | i: 23500 |                         LR: 0.00057 |                         Loss Val: 511.842 | Loss Avg: 537.878\n",
      "Batch: 0 | i: 23600 |                         LR: 0.00057 |                         Loss Val: 511.846 | Loss Avg: 537.767\n",
      "Batch: 0 | i: 23700 |                         LR: 0.00057 |                         Loss Val: 511.837 | Loss Avg: 537.658\n",
      "Batch: 0 | i: 23800 |                         LR: 0.00057 |                         Loss Val: 511.838 | Loss Avg: 537.549\n",
      "Batch: 0 | i: 23900 |                         LR: 0.00057 |                         Loss Val: 511.851 | Loss Avg: 537.442\n",
      "Batch: 0 | i: 24000 |                         LR: 0.00054 |                         Loss Val: 511.822 | Loss Avg: 537.335\n",
      "Batch: 0 | i: 24100 |                         LR: 0.00054 |                         Loss Val: 511.822 | Loss Avg: 537.229\n",
      "Batch: 0 | i: 24200 |                         LR: 0.00054 |                         Loss Val: 511.809 | Loss Avg: 537.124\n",
      "Batch: 0 | i: 24300 |                         LR: 0.00054 |                         Loss Val: 511.803 | Loss Avg: 537.020\n",
      "Batch: 0 | i: 24400 |                         LR: 0.00054 |                         Loss Val: 511.811 | Loss Avg: 536.917\n",
      "Batch: 0 | i: 24500 |                         LR: 0.00054 |                         Loss Val: 511.808 | Loss Avg: 536.814\n",
      "Batch: 0 | i: 24600 |                         LR: 0.00054 |                         Loss Val: 511.821 | Loss Avg: 536.713\n",
      "Batch: 0 | i: 24700 |                         LR: 0.00054 |                         Loss Val: 511.799 | Loss Avg: 536.612\n",
      "Batch: 0 | i: 24800 |                         LR: 0.00054 |                         Loss Val: 511.796 | Loss Avg: 536.512\n",
      "Batch: 0 | i: 24900 |                         LR: 0.00054 |                         Loss Val: 511.790 | Loss Avg: 536.413\n",
      "Batch: 0 | i: 25000 |                         LR: 0.00054 |                         Loss Val: 511.799 | Loss Avg: 536.314\n",
      "Batch: 0 | i: 25100 |                         LR: 0.00054 |                         Loss Val: 511.795 | Loss Avg: 536.217\n",
      "Batch: 0 | i: 25200 |                         LR: 0.00054 |                         Loss Val: 511.788 | Loss Avg: 536.120\n",
      "Batch: 0 | i: 25300 |                         LR: 0.00054 |                         Loss Val: 511.784 | Loss Avg: 536.023\n",
      "Batch: 0 | i: 25400 |                         LR: 0.00054 |                         Loss Val: 511.770 | Loss Avg: 535.928\n",
      "Batch: 0 | i: 25500 |                         LR: 0.00054 |                         Loss Val: 511.776 | Loss Avg: 535.833\n",
      "Batch: 0 | i: 25600 |                         LR: 0.00054 |                         Loss Val: 511.779 | Loss Avg: 535.739\n",
      "Batch: 0 | i: 25700 |                         LR: 0.00054 |                         Loss Val: 511.773 | Loss Avg: 535.646\n",
      "Batch: 0 | i: 25800 |                         LR: 0.00054 |                         Loss Val: 511.748 | Loss Avg: 535.554\n",
      "Batch: 0 | i: 25900 |                         LR: 0.00054 |                         Loss Val: 511.760 | Loss Avg: 535.462\n",
      "Batch: 0 | i: 26000 |                         LR: 0.00051 |                         Loss Val: 511.759 | Loss Avg: 535.371\n",
      "Batch: 0 | i: 26100 |                         LR: 0.00051 |                         Loss Val: 511.764 | Loss Avg: 535.280\n",
      "Batch: 0 | i: 26200 |                         LR: 0.00051 |                         Loss Val: 511.757 | Loss Avg: 535.190\n",
      "Batch: 0 | i: 26300 |                         LR: 0.00051 |                         Loss Val: 511.750 | Loss Avg: 535.101\n",
      "Batch: 0 | i: 26400 |                         LR: 0.00051 |                         Loss Val: 511.743 | Loss Avg: 535.013\n",
      "Batch: 0 | i: 26500 |                         LR: 0.00051 |                         Loss Val: 511.703 | Loss Avg: 534.925\n",
      "Batch: 0 | i: 26600 |                         LR: 0.00051 |                         Loss Val: 511.652 | Loss Avg: 534.837\n",
      "Batch: 0 | i: 26700 |                         LR: 0.00051 |                         Loss Val: 511.612 | Loss Avg: 534.750\n",
      "Batch: 0 | i: 26800 |                         LR: 0.00051 |                         Loss Val: 511.559 | Loss Avg: 534.664\n",
      "Batch: 0 | i: 26900 |                         LR: 0.00051 |                         Loss Val: 511.522 | Loss Avg: 534.578\n",
      "Batch: 0 | i: 27000 |                         LR: 0.00051 |                         Loss Val: 511.483 | Loss Avg: 534.493\n",
      "Batch: 0 | i: 27100 |                         LR: 0.00051 |                         Loss Val: 511.454 | Loss Avg: 534.408\n",
      "Batch: 0 | i: 27200 |                         LR: 0.00051 |                         Loss Val: 511.403 | Loss Avg: 534.323\n",
      "Batch: 0 | i: 27300 |                         LR: 0.00051 |                         Loss Val: 511.366 | Loss Avg: 534.239\n",
      "Batch: 0 | i: 27400 |                         LR: 0.00051 |                         Loss Val: 511.333 | Loss Avg: 534.156\n",
      "Batch: 0 | i: 27500 |                         LR: 0.00051 |                         Loss Val: 511.327 | Loss Avg: 534.073\n",
      "Batch: 0 | i: 27600 |                         LR: 0.00051 |                         Loss Val: 511.302 | Loss Avg: 533.990\n",
      "Batch: 0 | i: 27700 |                         LR: 0.00051 |                         Loss Val: 511.280 | Loss Avg: 533.908\n",
      "Batch: 0 | i: 27800 |                         LR: 0.00051 |                         Loss Val: 511.268 | Loss Avg: 533.827\n",
      "Batch: 0 | i: 27900 |                         LR: 0.00051 |                         Loss Val: 511.267 | Loss Avg: 533.746\n",
      "Batch: 0 | i: 28000 |                         LR: 0.00049 |                         Loss Val: 511.240 | Loss Avg: 533.666\n",
      "Batch: 0 | i: 28100 |                         LR: 0.00049 |                         Loss Val: 511.250 | Loss Avg: 533.586\n",
      "Batch: 0 | i: 28200 |                         LR: 0.00049 |                         Loss Val: 511.234 | Loss Avg: 533.507\n",
      "Batch: 0 | i: 28300 |                         LR: 0.00049 |                         Loss Val: 511.260 | Loss Avg: 533.428\n",
      "Batch: 0 | i: 28400 |                         LR: 0.00049 |                         Loss Val: 511.226 | Loss Avg: 533.350\n",
      "Batch: 0 | i: 28500 |                         LR: 0.00049 |                         Loss Val: 511.217 | Loss Avg: 533.272\n",
      "Batch: 0 | i: 28600 |                         LR: 0.00049 |                         Loss Val: 511.224 | Loss Avg: 533.195\n",
      "Batch: 0 | i: 28700 |                         LR: 0.00049 |                         Loss Val: 511.206 | Loss Avg: 533.118\n",
      "Batch: 0 | i: 28800 |                         LR: 0.00049 |                         Loss Val: 511.215 | Loss Avg: 533.042\n",
      "Batch: 0 | i: 28900 |                         LR: 0.00049 |                         Loss Val: 511.235 | Loss Avg: 532.967\n",
      "Batch: 0 | i: 29000 |                         LR: 0.00049 |                         Loss Val: 511.188 | Loss Avg: 532.892\n",
      "Batch: 0 | i: 29100 |                         LR: 0.00049 |                         Loss Val: 511.183 | Loss Avg: 532.817\n",
      "Batch: 0 | i: 29200 |                         LR: 0.00049 |                         Loss Val: 511.163 | Loss Avg: 532.743\n",
      "Batch: 0 | i: 29300 |                         LR: 0.00049 |                         Loss Val: 511.166 | Loss Avg: 532.670\n",
      "Batch: 0 | i: 29400 |                         LR: 0.00049 |                         Loss Val: 511.145 | Loss Avg: 532.596\n",
      "Batch: 0 | i: 29500 |                         LR: 0.00049 |                         Loss Val: 511.137 | Loss Avg: 532.524\n",
      "Batch: 0 | i: 29600 |                         LR: 0.00049 |                         Loss Val: 511.133 | Loss Avg: 532.451\n",
      "Batch: 0 | i: 29700 |                         LR: 0.00049 |                         Loss Val: 511.120 | Loss Avg: 532.380\n",
      "Batch: 0 | i: 29800 |                         LR: 0.00049 |                         Loss Val: 511.117 | Loss Avg: 532.308\n",
      "Batch: 0 | i: 29900 |                         LR: 0.00049 |                         Loss Val: 511.109 | Loss Avg: 532.237\n",
      "Batch: 0 | i: 30000 |                         LR: 0.00046 |                         Loss Val: 511.102 | Loss Avg: 532.167\n",
      "Batch: 0 | i: 30100 |                         LR: 0.00046 |                         Loss Val: 511.089 | Loss Avg: 532.097\n",
      "Batch: 0 | i: 30200 |                         LR: 0.00046 |                         Loss Val: 511.093 | Loss Avg: 532.027\n",
      "Batch: 0 | i: 30300 |                         LR: 0.00046 |                         Loss Val: 511.096 | Loss Avg: 531.958\n",
      "Batch: 0 | i: 30400 |                         LR: 0.00046 |                         Loss Val: 511.062 | Loss Avg: 531.890\n",
      "Batch: 0 | i: 30500 |                         LR: 0.00046 |                         Loss Val: 511.062 | Loss Avg: 531.821\n",
      "Batch: 0 | i: 30600 |                         LR: 0.00046 |                         Loss Val: 511.056 | Loss Avg: 531.754\n",
      "Batch: 0 | i: 30700 |                         LR: 0.00046 |                         Loss Val: 511.054 | Loss Avg: 531.686\n",
      "Batch: 0 | i: 30800 |                         LR: 0.00046 |                         Loss Val: 511.047 | Loss Avg: 531.619\n",
      "Batch: 0 | i: 30900 |                         LR: 0.00046 |                         Loss Val: 511.045 | Loss Avg: 531.553\n",
      "Batch: 0 | i: 31000 |                         LR: 0.00046 |                         Loss Val: 511.033 | Loss Avg: 531.486\n",
      "Batch: 0 | i: 31100 |                         LR: 0.00046 |                         Loss Val: 511.038 | Loss Avg: 531.421\n",
      "Batch: 0 | i: 31200 |                         LR: 0.00046 |                         Loss Val: 511.030 | Loss Avg: 531.355\n",
      "Batch: 0 | i: 31300 |                         LR: 0.00046 |                         Loss Val: 511.020 | Loss Avg: 531.290\n",
      "Batch: 0 | i: 31400 |                         LR: 0.00046 |                         Loss Val: 511.011 | Loss Avg: 531.226\n",
      "Batch: 0 | i: 31500 |                         LR: 0.00046 |                         Loss Val: 511.013 | Loss Avg: 531.162\n",
      "Batch: 0 | i: 31600 |                         LR: 0.00046 |                         Loss Val: 511.004 | Loss Avg: 531.098\n",
      "Batch: 0 | i: 31700 |                         LR: 0.00046 |                         Loss Val: 510.997 | Loss Avg: 531.034\n",
      "Batch: 0 | i: 31800 |                         LR: 0.00046 |                         Loss Val: 510.990 | Loss Avg: 530.971\n",
      "Batch: 0 | i: 31900 |                         LR: 0.00046 |                         Loss Val: 510.990 | Loss Avg: 530.909\n",
      "Batch: 0 | i: 32000 |                         LR: 0.00044 |                         Loss Val: 510.976 | Loss Avg: 530.846\n",
      "Batch: 0 | i: 32100 |                         LR: 0.00044 |                         Loss Val: 510.969 | Loss Avg: 530.784\n",
      "Batch: 0 | i: 32200 |                         LR: 0.00044 |                         Loss Val: 510.945 | Loss Avg: 530.723\n",
      "Batch: 0 | i: 32300 |                         LR: 0.00044 |                         Loss Val: 510.948 | Loss Avg: 530.662\n",
      "Batch: 0 | i: 32400 |                         LR: 0.00044 |                         Loss Val: 510.956 | Loss Avg: 530.601\n",
      "Batch: 0 | i: 32500 |                         LR: 0.00044 |                         Loss Val: 510.944 | Loss Avg: 530.540\n",
      "Batch: 0 | i: 32600 |                         LR: 0.00044 |                         Loss Val: 510.941 | Loss Avg: 530.480\n",
      "Batch: 0 | i: 32700 |                         LR: 0.00044 |                         Loss Val: 510.939 | Loss Avg: 530.420\n",
      "Batch: 0 | i: 32800 |                         LR: 0.00044 |                         Loss Val: 510.935 | Loss Avg: 530.361\n",
      "Batch: 0 | i: 32900 |                         LR: 0.00044 |                         Loss Val: 510.911 | Loss Avg: 530.302\n",
      "Batch: 0 | i: 33000 |                         LR: 0.00044 |                         Loss Val: 510.921 | Loss Avg: 530.243\n",
      "Batch: 0 | i: 33100 |                         LR: 0.00044 |                         Loss Val: 510.916 | Loss Avg: 530.185\n",
      "Batch: 0 | i: 33200 |                         LR: 0.00044 |                         Loss Val: 510.916 | Loss Avg: 530.127\n",
      "Batch: 0 | i: 33300 |                         LR: 0.00044 |                         Loss Val: 510.911 | Loss Avg: 530.069\n",
      "Batch: 0 | i: 33400 |                         LR: 0.00044 |                         Loss Val: 510.906 | Loss Avg: 530.012\n",
      "Batch: 0 | i: 33500 |                         LR: 0.00044 |                         Loss Val: 510.895 | Loss Avg: 529.955\n",
      "Batch: 0 | i: 33600 |                         LR: 0.00044 |                         Loss Val: 510.889 | Loss Avg: 529.898\n",
      "Batch: 0 | i: 33700 |                         LR: 0.00044 |                         Loss Val: 510.889 | Loss Avg: 529.842\n",
      "Batch: 0 | i: 33800 |                         LR: 0.00044 |                         Loss Val: 510.892 | Loss Avg: 529.786\n",
      "Batch: 0 | i: 33900 |                         LR: 0.00044 |                         Loss Val: 510.891 | Loss Avg: 529.730\n",
      "Batch: 0 | i: 34000 |                         LR: 0.00042 |                         Loss Val: 510.878 | Loss Avg: 529.674\n",
      "Batch: 0 | i: 34100 |                         LR: 0.00042 |                         Loss Val: 510.892 | Loss Avg: 529.619\n",
      "Batch: 0 | i: 34200 |                         LR: 0.00042 |                         Loss Val: 510.863 | Loss Avg: 529.564\n",
      "Batch: 0 | i: 34300 |                         LR: 0.00042 |                         Loss Val: 510.873 | Loss Avg: 529.510\n",
      "Batch: 0 | i: 34400 |                         LR: 0.00042 |                         Loss Val: 510.870 | Loss Avg: 529.456\n",
      "Batch: 0 | i: 34500 |                         LR: 0.00042 |                         Loss Val: 510.881 | Loss Avg: 529.402\n",
      "Batch: 0 | i: 34600 |                         LR: 0.00042 |                         Loss Val: 510.872 | Loss Avg: 529.348\n",
      "Batch: 0 | i: 34700 |                         LR: 0.00042 |                         Loss Val: 510.865 | Loss Avg: 529.295\n",
      "Batch: 0 | i: 34800 |                         LR: 0.00042 |                         Loss Val: 510.855 | Loss Avg: 529.242\n",
      "Batch: 0 | i: 34900 |                         LR: 0.00042 |                         Loss Val: 510.851 | Loss Avg: 529.189\n",
      "Batch: 0 | i: 35000 |                         LR: 0.00042 |                         Loss Val: 510.848 | Loss Avg: 529.137\n",
      "Batch: 0 | i: 35100 |                         LR: 0.00042 |                         Loss Val: 510.836 | Loss Avg: 529.085\n",
      "Batch: 0 | i: 35200 |                         LR: 0.00042 |                         Loss Val: 510.836 | Loss Avg: 529.033\n",
      "Batch: 0 | i: 35300 |                         LR: 0.00042 |                         Loss Val: 510.837 | Loss Avg: 528.982\n",
      "Batch: 0 | i: 35400 |                         LR: 0.00042 |                         Loss Val: 510.834 | Loss Avg: 528.930\n",
      "Batch: 0 | i: 35500 |                         LR: 0.00042 |                         Loss Val: 510.822 | Loss Avg: 528.879\n",
      "Batch: 0 | i: 35600 |                         LR: 0.00042 |                         Loss Val: 510.840 | Loss Avg: 528.829\n",
      "Batch: 0 | i: 35700 |                         LR: 0.00042 |                         Loss Val: 510.822 | Loss Avg: 528.778\n",
      "Batch: 0 | i: 35800 |                         LR: 0.00042 |                         Loss Val: 510.838 | Loss Avg: 528.728\n",
      "Batch: 0 | i: 35900 |                         LR: 0.00042 |                         Loss Val: 510.815 | Loss Avg: 528.678\n",
      "Batch: 0 | i: 36000 |                         LR: 0.00040 |                         Loss Val: 510.817 | Loss Avg: 528.629\n",
      "Batch: 0 | i: 36100 |                         LR: 0.00040 |                         Loss Val: 510.805 | Loss Avg: 528.579\n",
      "Batch: 0 | i: 36200 |                         LR: 0.00040 |                         Loss Val: 510.833 | Loss Avg: 528.530\n",
      "Batch: 0 | i: 36300 |                         LR: 0.00040 |                         Loss Val: 510.815 | Loss Avg: 528.481\n",
      "Batch: 0 | i: 36400 |                         LR: 0.00040 |                         Loss Val: 510.818 | Loss Avg: 528.433\n",
      "Batch: 0 | i: 36500 |                         LR: 0.00040 |                         Loss Val: 510.814 | Loss Avg: 528.385\n",
      "Batch: 0 | i: 36600 |                         LR: 0.00040 |                         Loss Val: 510.797 | Loss Avg: 528.337\n",
      "Batch: 0 | i: 36700 |                         LR: 0.00040 |                         Loss Val: 510.805 | Loss Avg: 528.289\n",
      "Batch: 0 | i: 36800 |                         LR: 0.00040 |                         Loss Val: 510.809 | Loss Avg: 528.241\n",
      "Batch: 0 | i: 36900 |                         LR: 0.00040 |                         Loss Val: 510.792 | Loss Avg: 528.194\n",
      "Batch: 0 | i: 37000 |                         LR: 0.00040 |                         Loss Val: 510.797 | Loss Avg: 528.147\n",
      "Batch: 0 | i: 37100 |                         LR: 0.00040 |                         Loss Val: 510.794 | Loss Avg: 528.100\n",
      "Batch: 0 | i: 37200 |                         LR: 0.00040 |                         Loss Val: 510.795 | Loss Avg: 528.054\n",
      "Batch: 0 | i: 37300 |                         LR: 0.00040 |                         Loss Val: 510.794 | Loss Avg: 528.007\n",
      "Batch: 0 | i: 37400 |                         LR: 0.00040 |                         Loss Val: 510.791 | Loss Avg: 527.961\n",
      "Batch: 0 | i: 37500 |                         LR: 0.00040 |                         Loss Val: 510.783 | Loss Avg: 527.916\n",
      "Batch: 0 | i: 37600 |                         LR: 0.00040 |                         Loss Val: 510.796 | Loss Avg: 527.870\n",
      "Batch: 0 | i: 37700 |                         LR: 0.00040 |                         Loss Val: 510.788 | Loss Avg: 527.825\n",
      "Batch: 0 | i: 37800 |                         LR: 0.00040 |                         Loss Val: 510.790 | Loss Avg: 527.780\n",
      "Batch: 0 | i: 37900 |                         LR: 0.00040 |                         Loss Val: 510.779 | Loss Avg: 527.735\n",
      "Batch: 0 | i: 38000 |                         LR: 0.00038 |                         Loss Val: 510.780 | Loss Avg: 527.690\n",
      "Batch: 0 | i: 38100 |                         LR: 0.00038 |                         Loss Val: 510.791 | Loss Avg: 527.646\n",
      "Batch: 0 | i: 38200 |                         LR: 0.00038 |                         Loss Val: 510.777 | Loss Avg: 527.602\n",
      "Batch: 0 | i: 38300 |                         LR: 0.00038 |                         Loss Val: 510.783 | Loss Avg: 527.558\n",
      "Batch: 0 | i: 38400 |                         LR: 0.00038 |                         Loss Val: 510.770 | Loss Avg: 527.514\n",
      "Batch: 0 | i: 38500 |                         LR: 0.00038 |                         Loss Val: 510.763 | Loss Avg: 527.471\n",
      "Batch: 0 | i: 38600 |                         LR: 0.00038 |                         Loss Val: 510.765 | Loss Avg: 527.427\n",
      "Batch: 0 | i: 38700 |                         LR: 0.00038 |                         Loss Val: 510.763 | Loss Avg: 527.384\n",
      "Batch: 0 | i: 38800 |                         LR: 0.00038 |                         Loss Val: 510.759 | Loss Avg: 527.341\n",
      "Batch: 0 | i: 38900 |                         LR: 0.00038 |                         Loss Val: 510.762 | Loss Avg: 527.299\n",
      "Batch: 0 | i: 39000 |                         LR: 0.00038 |                         Loss Val: 510.756 | Loss Avg: 527.256\n",
      "Batch: 0 | i: 39100 |                         LR: 0.00038 |                         Loss Val: 510.763 | Loss Avg: 527.214\n",
      "Batch: 0 | i: 39200 |                         LR: 0.00038 |                         Loss Val: 510.752 | Loss Avg: 527.172\n",
      "Batch: 0 | i: 39300 |                         LR: 0.00038 |                         Loss Val: 510.758 | Loss Avg: 527.130\n",
      "Batch: 0 | i: 39400 |                         LR: 0.00038 |                         Loss Val: 510.758 | Loss Avg: 527.089\n",
      "Batch: 0 | i: 39500 |                         LR: 0.00038 |                         Loss Val: 510.756 | Loss Avg: 527.048\n",
      "Batch: 0 | i: 39600 |                         LR: 0.00038 |                         Loss Val: 510.758 | Loss Avg: 527.006\n",
      "Batch: 0 | i: 39700 |                         LR: 0.00038 |                         Loss Val: 510.753 | Loss Avg: 526.965\n",
      "Batch: 0 | i: 39800 |                         LR: 0.00038 |                         Loss Val: 510.741 | Loss Avg: 526.925\n",
      "Batch: 0 | i: 39900 |                         LR: 0.00038 |                         Loss Val: 510.746 | Loss Avg: 526.884\n",
      "Batch: 0 | i: 40000 |                         LR: 0.00036 |                         Loss Val: 510.739 | Loss Avg: 526.844\n",
      "Batch: 0 | i: 40100 |                         LR: 0.00036 |                         Loss Val: 510.743 | Loss Avg: 526.804\n",
      "Batch: 0 | i: 40200 |                         LR: 0.00036 |                         Loss Val: 510.749 | Loss Avg: 526.764\n",
      "Batch: 0 | i: 40300 |                         LR: 0.00036 |                         Loss Val: 510.740 | Loss Avg: 526.724\n",
      "Batch: 0 | i: 40400 |                         LR: 0.00036 |                         Loss Val: 510.732 | Loss Avg: 526.684\n",
      "Batch: 0 | i: 40500 |                         LR: 0.00036 |                         Loss Val: 510.738 | Loss Avg: 526.645\n",
      "Batch: 0 | i: 40600 |                         LR: 0.00036 |                         Loss Val: 510.736 | Loss Avg: 526.606\n",
      "Batch: 0 | i: 40700 |                         LR: 0.00036 |                         Loss Val: 510.729 | Loss Avg: 526.567\n",
      "Batch: 0 | i: 40800 |                         LR: 0.00036 |                         Loss Val: 510.733 | Loss Avg: 526.528\n",
      "Batch: 0 | i: 40900 |                         LR: 0.00036 |                         Loss Val: 510.718 | Loss Avg: 526.489\n",
      "Batch: 0 | i: 41000 |                         LR: 0.00036 |                         Loss Val: 510.717 | Loss Avg: 526.451\n",
      "Batch: 0 | i: 41100 |                         LR: 0.00036 |                         Loss Val: 510.727 | Loss Avg: 526.413\n",
      "Batch: 0 | i: 41200 |                         LR: 0.00036 |                         Loss Val: 510.718 | Loss Avg: 526.375\n",
      "Batch: 0 | i: 41300 |                         LR: 0.00036 |                         Loss Val: 510.707 | Loss Avg: 526.337\n",
      "Batch: 0 | i: 41400 |                         LR: 0.00036 |                         Loss Val: 510.712 | Loss Avg: 526.299\n",
      "Batch: 0 | i: 41500 |                         LR: 0.00036 |                         Loss Val: 510.702 | Loss Avg: 526.261\n",
      "Batch: 0 | i: 41600 |                         LR: 0.00036 |                         Loss Val: 510.706 | Loss Avg: 526.224\n",
      "Batch: 0 | i: 41700 |                         LR: 0.00036 |                         Loss Val: 510.696 | Loss Avg: 526.187\n",
      "Batch: 0 | i: 41800 |                         LR: 0.00036 |                         Loss Val: 510.694 | Loss Avg: 526.150\n",
      "Batch: 0 | i: 41900 |                         LR: 0.00036 |                         Loss Val: 510.693 | Loss Avg: 526.113\n",
      "Batch: 0 | i: 42000 |                         LR: 0.00034 |                         Loss Val: 510.693 | Loss Avg: 526.076\n",
      "Batch: 0 | i: 42100 |                         LR: 0.00034 |                         Loss Val: 510.692 | Loss Avg: 526.040\n",
      "Batch: 0 | i: 42200 |                         LR: 0.00034 |                         Loss Val: 510.677 | Loss Avg: 526.003\n",
      "Batch: 0 | i: 42300 |                         LR: 0.00034 |                         Loss Val: 510.695 | Loss Avg: 525.967\n",
      "Batch: 0 | i: 42400 |                         LR: 0.00034 |                         Loss Val: 510.684 | Loss Avg: 525.931\n",
      "Batch: 0 | i: 42500 |                         LR: 0.00034 |                         Loss Val: 510.678 | Loss Avg: 525.895\n",
      "Batch: 0 | i: 42600 |                         LR: 0.00034 |                         Loss Val: 510.683 | Loss Avg: 525.859\n",
      "Batch: 0 | i: 42700 |                         LR: 0.00034 |                         Loss Val: 510.678 | Loss Avg: 525.824\n",
      "Batch: 0 | i: 42800 |                         LR: 0.00034 |                         Loss Val: 510.679 | Loss Avg: 525.788\n",
      "Batch: 0 | i: 42900 |                         LR: 0.00034 |                         Loss Val: 510.676 | Loss Avg: 525.753\n",
      "Batch: 0 | i: 43000 |                         LR: 0.00034 |                         Loss Val: 510.674 | Loss Avg: 525.718\n",
      "Batch: 0 | i: 43100 |                         LR: 0.00034 |                         Loss Val: 510.671 | Loss Avg: 525.683\n",
      "Batch: 0 | i: 43200 |                         LR: 0.00034 |                         Loss Val: 510.670 | Loss Avg: 525.648\n",
      "Batch: 0 | i: 43300 |                         LR: 0.00034 |                         Loss Val: 510.665 | Loss Avg: 525.614\n",
      "Batch: 0 | i: 43400 |                         LR: 0.00034 |                         Loss Val: 510.661 | Loss Avg: 525.579\n",
      "Batch: 0 | i: 43500 |                         LR: 0.00034 |                         Loss Val: 510.662 | Loss Avg: 525.545\n",
      "Batch: 0 | i: 43600 |                         LR: 0.00034 |                         Loss Val: 510.662 | Loss Avg: 525.511\n",
      "Batch: 0 | i: 43700 |                         LR: 0.00034 |                         Loss Val: 510.664 | Loss Avg: 525.477\n",
      "Batch: 0 | i: 43800 |                         LR: 0.00034 |                         Loss Val: 510.660 | Loss Avg: 525.443\n",
      "Batch: 0 | i: 43900 |                         LR: 0.00034 |                         Loss Val: 510.654 | Loss Avg: 525.410\n",
      "Batch: 0 | i: 44000 |                         LR: 0.00032 |                         Loss Val: 510.661 | Loss Avg: 525.376\n",
      "Batch: 0 | i: 44100 |                         LR: 0.00032 |                         Loss Val: 510.664 | Loss Avg: 525.343\n",
      "Batch: 0 | i: 44200 |                         LR: 0.00032 |                         Loss Val: 510.651 | Loss Avg: 525.309\n",
      "Batch: 0 | i: 44300 |                         LR: 0.00032 |                         Loss Val: 510.656 | Loss Avg: 525.276\n",
      "Batch: 0 | i: 44400 |                         LR: 0.00032 |                         Loss Val: 510.652 | Loss Avg: 525.243\n",
      "Batch: 0 | i: 44500 |                         LR: 0.00032 |                         Loss Val: 510.641 | Loss Avg: 525.211\n",
      "Batch: 0 | i: 44600 |                         LR: 0.00032 |                         Loss Val: 510.641 | Loss Avg: 525.178\n",
      "Batch: 0 | i: 44700 |                         LR: 0.00032 |                         Loss Val: 510.648 | Loss Avg: 525.145\n",
      "Batch: 0 | i: 44800 |                         LR: 0.00032 |                         Loss Val: 510.647 | Loss Avg: 525.113\n",
      "Batch: 0 | i: 44900 |                         LR: 0.00032 |                         Loss Val: 510.642 | Loss Avg: 525.081\n",
      "Batch: 0 | i: 45000 |                         LR: 0.00032 |                         Loss Val: 510.655 | Loss Avg: 525.049\n",
      "Batch: 0 | i: 45100 |                         LR: 0.00032 |                         Loss Val: 510.639 | Loss Avg: 525.017\n",
      "Batch: 0 | i: 45200 |                         LR: 0.00032 |                         Loss Val: 510.636 | Loss Avg: 524.985\n",
      "Batch: 0 | i: 45300 |                         LR: 0.00032 |                         Loss Val: 510.640 | Loss Avg: 524.953\n",
      "Batch: 0 | i: 45400 |                         LR: 0.00032 |                         Loss Val: 510.642 | Loss Avg: 524.922\n",
      "Batch: 0 | i: 45500 |                         LR: 0.00032 |                         Loss Val: 510.630 | Loss Avg: 524.890\n",
      "Batch: 0 | i: 45600 |                         LR: 0.00032 |                         Loss Val: 510.627 | Loss Avg: 524.859\n",
      "Batch: 0 | i: 45700 |                         LR: 0.00032 |                         Loss Val: 510.629 | Loss Avg: 524.828\n",
      "Batch: 0 | i: 45800 |                         LR: 0.00032 |                         Loss Val: 510.627 | Loss Avg: 524.797\n",
      "Batch: 0 | i: 45900 |                         LR: 0.00032 |                         Loss Val: 510.628 | Loss Avg: 524.766\n",
      "Batch: 0 | i: 46000 |                         LR: 0.00031 |                         Loss Val: 510.628 | Loss Avg: 524.735\n",
      "Batch: 0 | i: 46100 |                         LR: 0.00031 |                         Loss Val: 510.620 | Loss Avg: 524.705\n",
      "Batch: 0 | i: 46200 |                         LR: 0.00031 |                         Loss Val: 510.626 | Loss Avg: 524.674\n",
      "Batch: 0 | i: 46300 |                         LR: 0.00031 |                         Loss Val: 510.625 | Loss Avg: 524.644\n",
      "Batch: 0 | i: 46400 |                         LR: 0.00031 |                         Loss Val: 510.631 | Loss Avg: 524.614\n",
      "Batch: 0 | i: 46500 |                         LR: 0.00031 |                         Loss Val: 510.627 | Loss Avg: 524.584\n",
      "Batch: 0 | i: 46600 |                         LR: 0.00031 |                         Loss Val: 510.615 | Loss Avg: 524.554\n",
      "Batch: 0 | i: 46700 |                         LR: 0.00031 |                         Loss Val: 510.620 | Loss Avg: 524.524\n",
      "Batch: 0 | i: 46800 |                         LR: 0.00031 |                         Loss Val: 510.623 | Loss Avg: 524.494\n",
      "Batch: 0 | i: 46900 |                         LR: 0.00031 |                         Loss Val: 510.625 | Loss Avg: 524.465\n",
      "Batch: 0 | i: 47000 |                         LR: 0.00031 |                         Loss Val: 510.618 | Loss Avg: 524.435\n",
      "Batch: 0 | i: 47100 |                         LR: 0.00031 |                         Loss Val: 510.616 | Loss Avg: 524.406\n",
      "Batch: 0 | i: 47200 |                         LR: 0.00031 |                         Loss Val: 510.613 | Loss Avg: 524.377\n",
      "Batch: 0 | i: 47300 |                         LR: 0.00031 |                         Loss Val: 510.610 | Loss Avg: 524.347\n",
      "Batch: 0 | i: 47400 |                         LR: 0.00031 |                         Loss Val: 510.618 | Loss Avg: 524.319\n",
      "Batch: 0 | i: 47500 |                         LR: 0.00031 |                         Loss Val: 510.623 | Loss Avg: 524.290\n",
      "Batch: 0 | i: 47600 |                         LR: 0.00031 |                         Loss Val: 510.615 | Loss Avg: 524.261\n",
      "Batch: 0 | i: 47700 |                         LR: 0.00031 |                         Loss Val: 510.613 | Loss Avg: 524.232\n",
      "Batch: 0 | i: 47800 |                         LR: 0.00031 |                         Loss Val: 510.608 | Loss Avg: 524.204\n",
      "Batch: 0 | i: 47900 |                         LR: 0.00031 |                         Loss Val: 510.607 | Loss Avg: 524.175\n",
      "Batch: 0 | i: 48000 |                         LR: 0.00029 |                         Loss Val: 510.602 | Loss Avg: 524.147\n",
      "Batch: 0 | i: 48100 |                         LR: 0.00029 |                         Loss Val: 510.612 | Loss Avg: 524.119\n",
      "Batch: 0 | i: 48200 |                         LR: 0.00029 |                         Loss Val: 510.609 | Loss Avg: 524.091\n",
      "Batch: 0 | i: 48300 |                         LR: 0.00029 |                         Loss Val: 510.603 | Loss Avg: 524.063\n",
      "Batch: 0 | i: 48400 |                         LR: 0.00029 |                         Loss Val: 510.608 | Loss Avg: 524.035\n",
      "Batch: 0 | i: 48500 |                         LR: 0.00029 |                         Loss Val: 510.603 | Loss Avg: 524.008\n",
      "Batch: 0 | i: 48600 |                         LR: 0.00029 |                         Loss Val: 510.600 | Loss Avg: 523.980\n",
      "Batch: 0 | i: 48700 |                         LR: 0.00029 |                         Loss Val: 510.605 | Loss Avg: 523.953\n",
      "Batch: 0 | i: 48800 |                         LR: 0.00029 |                         Loss Val: 510.604 | Loss Avg: 523.925\n",
      "Batch: 0 | i: 48900 |                         LR: 0.00029 |                         Loss Val: 510.600 | Loss Avg: 523.898\n",
      "Batch: 0 | i: 49000 |                         LR: 0.00029 |                         Loss Val: 510.603 | Loss Avg: 523.871\n",
      "Batch: 0 | i: 49100 |                         LR: 0.00029 |                         Loss Val: 510.596 | Loss Avg: 523.844\n",
      "Batch: 0 | i: 49200 |                         LR: 0.00029 |                         Loss Val: 510.604 | Loss Avg: 523.817\n",
      "Batch: 0 | i: 49300 |                         LR: 0.00029 |                         Loss Val: 510.600 | Loss Avg: 523.790\n",
      "Batch: 0 | i: 49400 |                         LR: 0.00029 |                         Loss Val: 510.606 | Loss Avg: 523.763\n",
      "Batch: 0 | i: 49500 |                         LR: 0.00029 |                         Loss Val: 510.594 | Loss Avg: 523.737\n",
      "Batch: 0 | i: 49600 |                         LR: 0.00029 |                         Loss Val: 510.609 | Loss Avg: 523.710\n",
      "Batch: 0 | i: 49700 |                         LR: 0.00029 |                         Loss Val: 510.594 | Loss Avg: 523.684\n",
      "Batch: 0 | i: 49800 |                         LR: 0.00029 |                         Loss Val: 510.604 | Loss Avg: 523.658\n",
      "Batch: 0 | i: 49900 |                         LR: 0.00029 |                         Loss Val: 510.597 | Loss Avg: 523.631\n",
      "Batch: 0 | i: 50000 |                         LR: 0.00028 |                         Loss Val: 510.601 | Loss Avg: 523.605\n",
      "Batch: 0 | i: 50100 |                         LR: 0.00028 |                         Loss Val: 510.594 | Loss Avg: 523.579\n",
      "Batch: 0 | i: 50200 |                         LR: 0.00028 |                         Loss Val: 510.602 | Loss Avg: 523.554\n",
      "Batch: 0 | i: 50300 |                         LR: 0.00028 |                         Loss Val: 510.596 | Loss Avg: 523.528\n",
      "Batch: 0 | i: 50400 |                         LR: 0.00028 |                         Loss Val: 510.586 | Loss Avg: 523.502\n",
      "Batch: 0 | i: 50500 |                         LR: 0.00028 |                         Loss Val: 510.586 | Loss Avg: 523.477\n",
      "Batch: 0 | i: 50600 |                         LR: 0.00028 |                         Loss Val: 510.591 | Loss Avg: 523.451\n",
      "Batch: 0 | i: 50700 |                         LR: 0.00028 |                         Loss Val: 510.590 | Loss Avg: 523.426\n",
      "Batch: 0 | i: 50800 |                         LR: 0.00028 |                         Loss Val: 510.600 | Loss Avg: 523.400\n",
      "Batch: 0 | i: 50900 |                         LR: 0.00028 |                         Loss Val: 510.591 | Loss Avg: 523.375\n",
      "Batch: 0 | i: 51000 |                         LR: 0.00028 |                         Loss Val: 510.583 | Loss Avg: 523.350\n",
      "Batch: 0 | i: 51100 |                         LR: 0.00028 |                         Loss Val: 510.594 | Loss Avg: 523.325\n",
      "Batch: 0 | i: 51200 |                         LR: 0.00028 |                         Loss Val: 510.583 | Loss Avg: 523.300\n",
      "Batch: 0 | i: 51300 |                         LR: 0.00028 |                         Loss Val: 510.591 | Loss Avg: 523.276\n",
      "Batch: 0 | i: 51400 |                         LR: 0.00028 |                         Loss Val: 510.585 | Loss Avg: 523.251\n",
      "Batch: 0 | i: 51500 |                         LR: 0.00028 |                         Loss Val: 510.579 | Loss Avg: 523.226\n",
      "Batch: 0 | i: 51600 |                         LR: 0.00028 |                         Loss Val: 510.588 | Loss Avg: 523.202\n",
      "Batch: 0 | i: 51700 |                         LR: 0.00028 |                         Loss Val: 510.588 | Loss Avg: 523.177\n",
      "Batch: 0 | i: 51800 |                         LR: 0.00028 |                         Loss Val: 510.578 | Loss Avg: 523.153\n",
      "Batch: 0 | i: 51900 |                         LR: 0.00028 |                         Loss Val: 510.574 | Loss Avg: 523.129\n",
      "Batch: 0 | i: 52000 |                         LR: 0.00026 |                         Loss Val: 510.577 | Loss Avg: 523.105\n",
      "Batch: 0 | i: 52100 |                         LR: 0.00026 |                         Loss Val: 510.582 | Loss Avg: 523.081\n",
      "Batch: 0 | i: 52200 |                         LR: 0.00026 |                         Loss Val: 510.585 | Loss Avg: 523.057\n",
      "Batch: 0 | i: 52300 |                         LR: 0.00026 |                         Loss Val: 510.582 | Loss Avg: 523.033\n",
      "Batch: 0 | i: 52400 |                         LR: 0.00026 |                         Loss Val: 510.583 | Loss Avg: 523.009\n",
      "Batch: 0 | i: 52500 |                         LR: 0.00026 |                         Loss Val: 510.582 | Loss Avg: 522.986\n",
      "Batch: 0 | i: 52600 |                         LR: 0.00026 |                         Loss Val: 510.577 | Loss Avg: 522.962\n",
      "Batch: 0 | i: 52700 |                         LR: 0.00026 |                         Loss Val: 510.579 | Loss Avg: 522.938\n",
      "Batch: 0 | i: 52800 |                         LR: 0.00026 |                         Loss Val: 510.580 | Loss Avg: 522.915\n",
      "Batch: 0 | i: 52900 |                         LR: 0.00026 |                         Loss Val: 510.579 | Loss Avg: 522.892\n",
      "Batch: 0 | i: 53000 |                         LR: 0.00026 |                         Loss Val: 510.576 | Loss Avg: 522.868\n",
      "Batch: 0 | i: 53100 |                         LR: 0.00026 |                         Loss Val: 510.579 | Loss Avg: 522.845\n",
      "Batch: 0 | i: 53200 |                         LR: 0.00026 |                         Loss Val: 510.580 | Loss Avg: 522.822\n",
      "Batch: 0 | i: 53300 |                         LR: 0.00026 |                         Loss Val: 510.580 | Loss Avg: 522.799\n",
      "Batch: 0 | i: 53400 |                         LR: 0.00026 |                         Loss Val: 510.585 | Loss Avg: 522.776\n",
      "Batch: 0 | i: 53500 |                         LR: 0.00026 |                         Loss Val: 510.576 | Loss Avg: 522.754\n",
      "Batch: 0 | i: 53600 |                         LR: 0.00026 |                         Loss Val: 510.570 | Loss Avg: 522.731\n",
      "Batch: 0 | i: 53700 |                         LR: 0.00026 |                         Loss Val: 510.568 | Loss Avg: 522.708\n",
      "Batch: 0 | i: 53800 |                         LR: 0.00026 |                         Loss Val: 510.568 | Loss Avg: 522.686\n",
      "Batch: 0 | i: 53900 |                         LR: 0.00026 |                         Loss Val: 510.577 | Loss Avg: 522.663\n",
      "Batch: 0 | i: 54000 |                         LR: 0.00025 |                         Loss Val: 510.572 | Loss Avg: 522.641\n",
      "Batch: 0 | i: 54100 |                         LR: 0.00025 |                         Loss Val: 510.569 | Loss Avg: 522.619\n",
      "Batch: 0 | i: 54200 |                         LR: 0.00025 |                         Loss Val: 510.574 | Loss Avg: 522.596\n",
      "Batch: 0 | i: 54300 |                         LR: 0.00025 |                         Loss Val: 510.565 | Loss Avg: 522.574\n",
      "Batch: 0 | i: 54400 |                         LR: 0.00025 |                         Loss Val: 510.564 | Loss Avg: 522.552\n",
      "Batch: 0 | i: 54500 |                         LR: 0.00025 |                         Loss Val: 510.564 | Loss Avg: 522.530\n",
      "Batch: 0 | i: 54600 |                         LR: 0.00025 |                         Loss Val: 510.569 | Loss Avg: 522.508\n",
      "Batch: 0 | i: 54700 |                         LR: 0.00025 |                         Loss Val: 510.563 | Loss Avg: 522.486\n",
      "Batch: 0 | i: 54800 |                         LR: 0.00025 |                         Loss Val: 510.561 | Loss Avg: 522.465\n",
      "Batch: 0 | i: 54900 |                         LR: 0.00025 |                         Loss Val: 510.578 | Loss Avg: 522.443\n",
      "Batch: 0 | i: 55000 |                         LR: 0.00025 |                         Loss Val: 510.567 | Loss Avg: 522.421\n",
      "Batch: 0 | i: 55100 |                         LR: 0.00025 |                         Loss Val: 510.572 | Loss Avg: 522.400\n",
      "Batch: 0 | i: 55200 |                         LR: 0.00025 |                         Loss Val: 510.566 | Loss Avg: 522.378\n",
      "Batch: 0 | i: 55300 |                         LR: 0.00025 |                         Loss Val: 510.560 | Loss Avg: 522.357\n",
      "Batch: 0 | i: 55400 |                         LR: 0.00025 |                         Loss Val: 510.559 | Loss Avg: 522.336\n",
      "Batch: 0 | i: 55500 |                         LR: 0.00025 |                         Loss Val: 510.564 | Loss Avg: 522.315\n",
      "Batch: 0 | i: 55600 |                         LR: 0.00025 |                         Loss Val: 510.565 | Loss Avg: 522.293\n",
      "Batch: 0 | i: 55700 |                         LR: 0.00025 |                         Loss Val: 510.558 | Loss Avg: 522.272\n",
      "Batch: 0 | i: 55800 |                         LR: 0.00025 |                         Loss Val: 510.558 | Loss Avg: 522.251\n",
      "Batch: 0 | i: 55900 |                         LR: 0.00025 |                         Loss Val: 510.569 | Loss Avg: 522.230\n",
      "Batch: 0 | i: 56000 |                         LR: 0.00024 |                         Loss Val: 510.564 | Loss Avg: 522.210\n",
      "Batch: 0 | i: 56100 |                         LR: 0.00024 |                         Loss Val: 510.561 | Loss Avg: 522.189\n",
      "Batch: 0 | i: 56200 |                         LR: 0.00024 |                         Loss Val: 510.559 | Loss Avg: 522.168\n",
      "Batch: 0 | i: 56300 |                         LR: 0.00024 |                         Loss Val: 510.557 | Loss Avg: 522.148\n",
      "Batch: 0 | i: 56400 |                         LR: 0.00024 |                         Loss Val: 510.564 | Loss Avg: 522.127\n",
      "Batch: 0 | i: 56500 |                         LR: 0.00024 |                         Loss Val: 510.559 | Loss Avg: 522.107\n",
      "Batch: 0 | i: 56600 |                         LR: 0.00024 |                         Loss Val: 510.557 | Loss Avg: 522.086\n",
      "Batch: 0 | i: 56700 |                         LR: 0.00024 |                         Loss Val: 510.558 | Loss Avg: 522.066\n",
      "Batch: 0 | i: 56800 |                         LR: 0.00024 |                         Loss Val: 510.557 | Loss Avg: 522.046\n",
      "Batch: 0 | i: 56900 |                         LR: 0.00024 |                         Loss Val: 510.556 | Loss Avg: 522.025\n",
      "Batch: 0 | i: 57000 |                         LR: 0.00024 |                         Loss Val: 510.557 | Loss Avg: 522.005\n",
      "Batch: 0 | i: 57100 |                         LR: 0.00024 |                         Loss Val: 510.560 | Loss Avg: 521.985\n",
      "Batch: 0 | i: 57200 |                         LR: 0.00024 |                         Loss Val: 510.553 | Loss Avg: 521.965\n",
      "Batch: 0 | i: 57300 |                         LR: 0.00024 |                         Loss Val: 510.556 | Loss Avg: 521.945\n",
      "Batch: 0 | i: 57400 |                         LR: 0.00024 |                         Loss Val: 510.551 | Loss Avg: 521.925\n",
      "Batch: 0 | i: 57500 |                         LR: 0.00024 |                         Loss Val: 510.552 | Loss Avg: 521.906\n",
      "Batch: 0 | i: 57600 |                         LR: 0.00024 |                         Loss Val: 510.556 | Loss Avg: 521.886\n",
      "Batch: 0 | i: 57700 |                         LR: 0.00024 |                         Loss Val: 510.556 | Loss Avg: 521.866\n",
      "Batch: 0 | i: 57800 |                         LR: 0.00024 |                         Loss Val: 510.558 | Loss Avg: 521.847\n",
      "Batch: 0 | i: 57900 |                         LR: 0.00024 |                         Loss Val: 510.555 | Loss Avg: 521.827\n",
      "Batch: 0 | i: 58000 |                         LR: 0.00023 |                         Loss Val: 510.556 | Loss Avg: 521.808\n",
      "Batch: 0 | i: 58100 |                         LR: 0.00023 |                         Loss Val: 510.551 | Loss Avg: 521.788\n",
      "Batch: 0 | i: 58200 |                         LR: 0.00023 |                         Loss Val: 510.551 | Loss Avg: 521.769\n",
      "Batch: 0 | i: 58300 |                         LR: 0.00023 |                         Loss Val: 510.552 | Loss Avg: 521.750\n",
      "Batch: 0 | i: 58400 |                         LR: 0.00023 |                         Loss Val: 510.549 | Loss Avg: 521.731\n",
      "Batch: 0 | i: 58500 |                         LR: 0.00023 |                         Loss Val: 510.548 | Loss Avg: 521.712\n",
      "Batch: 0 | i: 58600 |                         LR: 0.00023 |                         Loss Val: 510.552 | Loss Avg: 521.693\n",
      "Batch: 0 | i: 58700 |                         LR: 0.00023 |                         Loss Val: 510.551 | Loss Avg: 521.674\n",
      "Batch: 0 | i: 58800 |                         LR: 0.00023 |                         Loss Val: 510.548 | Loss Avg: 521.655\n",
      "Batch: 0 | i: 58900 |                         LR: 0.00023 |                         Loss Val: 510.550 | Loss Avg: 521.636\n",
      "Batch: 0 | i: 59000 |                         LR: 0.00023 |                         Loss Val: 510.550 | Loss Avg: 521.617\n",
      "Batch: 0 | i: 59100 |                         LR: 0.00023 |                         Loss Val: 510.550 | Loss Avg: 521.598\n",
      "Batch: 0 | i: 59200 |                         LR: 0.00023 |                         Loss Val: 510.545 | Loss Avg: 521.580\n",
      "Batch: 0 | i: 59300 |                         LR: 0.00023 |                         Loss Val: 510.549 | Loss Avg: 521.561\n",
      "Batch: 0 | i: 59400 |                         LR: 0.00023 |                         Loss Val: 510.554 | Loss Avg: 521.543\n",
      "Batch: 0 | i: 59500 |                         LR: 0.00023 |                         Loss Val: 510.551 | Loss Avg: 521.524\n",
      "Batch: 0 | i: 59600 |                         LR: 0.00023 |                         Loss Val: 510.554 | Loss Avg: 521.506\n",
      "Batch: 0 | i: 59700 |                         LR: 0.00023 |                         Loss Val: 510.545 | Loss Avg: 521.487\n",
      "Batch: 0 | i: 59800 |                         LR: 0.00023 |                         Loss Val: 510.545 | Loss Avg: 521.469\n",
      "Batch: 0 | i: 59900 |                         LR: 0.00023 |                         Loss Val: 510.543 | Loss Avg: 521.451\n",
      "Batch: 0 | i: 60000 |                         LR: 0.00021 |                         Loss Val: 510.552 | Loss Avg: 521.433\n",
      "Batch: 0 | i: 60100 |                         LR: 0.00021 |                         Loss Val: 510.540 | Loss Avg: 521.414\n",
      "Batch: 0 | i: 60200 |                         LR: 0.00021 |                         Loss Val: 510.555 | Loss Avg: 521.396\n",
      "Batch: 0 | i: 60300 |                         LR: 0.00021 |                         Loss Val: 510.548 | Loss Avg: 521.378\n",
      "Batch: 0 | i: 60400 |                         LR: 0.00021 |                         Loss Val: 510.546 | Loss Avg: 521.361\n",
      "Batch: 0 | i: 60500 |                         LR: 0.00021 |                         Loss Val: 510.540 | Loss Avg: 521.343\n",
      "Batch: 0 | i: 60600 |                         LR: 0.00021 |                         Loss Val: 510.539 | Loss Avg: 521.325\n",
      "Batch: 0 | i: 60700 |                         LR: 0.00021 |                         Loss Val: 510.539 | Loss Avg: 521.307\n",
      "Batch: 0 | i: 60800 |                         LR: 0.00021 |                         Loss Val: 510.549 | Loss Avg: 521.289\n",
      "Batch: 0 | i: 60900 |                         LR: 0.00021 |                         Loss Val: 510.544 | Loss Avg: 521.272\n",
      "Batch: 0 | i: 61000 |                         LR: 0.00021 |                         Loss Val: 510.541 | Loss Avg: 521.254\n",
      "Batch: 0 | i: 61100 |                         LR: 0.00021 |                         Loss Val: 510.546 | Loss Avg: 521.237\n",
      "Batch: 0 | i: 61200 |                         LR: 0.00021 |                         Loss Val: 510.544 | Loss Avg: 521.219\n",
      "Batch: 0 | i: 61300 |                         LR: 0.00021 |                         Loss Val: 510.543 | Loss Avg: 521.202\n",
      "Batch: 0 | i: 61400 |                         LR: 0.00021 |                         Loss Val: 510.541 | Loss Avg: 521.184\n",
      "Batch: 0 | i: 61500 |                         LR: 0.00021 |                         Loss Val: 510.545 | Loss Avg: 521.167\n",
      "Batch: 0 | i: 61600 |                         LR: 0.00021 |                         Loss Val: 510.539 | Loss Avg: 521.150\n",
      "Batch: 0 | i: 61700 |                         LR: 0.00021 |                         Loss Val: 510.544 | Loss Avg: 521.133\n",
      "Batch: 0 | i: 61800 |                         LR: 0.00021 |                         Loss Val: 510.546 | Loss Avg: 521.115\n",
      "Batch: 0 | i: 61900 |                         LR: 0.00021 |                         Loss Val: 510.538 | Loss Avg: 521.098\n",
      "Batch: 0 | i: 62000 |                         LR: 0.00020 |                         Loss Val: 510.543 | Loss Avg: 521.081\n",
      "Batch: 0 | i: 62100 |                         LR: 0.00020 |                         Loss Val: 510.534 | Loss Avg: 521.064\n",
      "Batch: 0 | i: 62200 |                         LR: 0.00020 |                         Loss Val: 510.539 | Loss Avg: 521.047\n",
      "Batch: 0 | i: 62300 |                         LR: 0.00020 |                         Loss Val: 510.542 | Loss Avg: 521.031\n",
      "Batch: 0 | i: 62400 |                         LR: 0.00020 |                         Loss Val: 510.545 | Loss Avg: 521.014\n",
      "Batch: 0 | i: 62500 |                         LR: 0.00020 |                         Loss Val: 510.536 | Loss Avg: 520.997\n",
      "Batch: 0 | i: 62600 |                         LR: 0.00020 |                         Loss Val: 510.537 | Loss Avg: 520.980\n",
      "Batch: 0 | i: 62700 |                         LR: 0.00020 |                         Loss Val: 510.535 | Loss Avg: 520.964\n",
      "Batch: 0 | i: 62800 |                         LR: 0.00020 |                         Loss Val: 510.545 | Loss Avg: 520.947\n",
      "Batch: 0 | i: 62900 |                         LR: 0.00020 |                         Loss Val: 510.538 | Loss Avg: 520.930\n",
      "Batch: 0 | i: 63000 |                         LR: 0.00020 |                         Loss Val: 510.542 | Loss Avg: 520.914\n",
      "Batch: 0 | i: 63100 |                         LR: 0.00020 |                         Loss Val: 510.535 | Loss Avg: 520.898\n",
      "Batch: 0 | i: 63200 |                         LR: 0.00020 |                         Loss Val: 510.535 | Loss Avg: 520.881\n",
      "Batch: 0 | i: 63300 |                         LR: 0.00020 |                         Loss Val: 510.540 | Loss Avg: 520.865\n",
      "Batch: 0 | i: 63400 |                         LR: 0.00020 |                         Loss Val: 510.537 | Loss Avg: 520.849\n",
      "Batch: 0 | i: 63500 |                         LR: 0.00020 |                         Loss Val: 510.532 | Loss Avg: 520.832\n",
      "Batch: 0 | i: 63600 |                         LR: 0.00020 |                         Loss Val: 510.536 | Loss Avg: 520.816\n",
      "Batch: 0 | i: 63700 |                         LR: 0.00020 |                         Loss Val: 510.538 | Loss Avg: 520.800\n",
      "Batch: 0 | i: 63800 |                         LR: 0.00020 |                         Loss Val: 510.531 | Loss Avg: 520.784\n",
      "Batch: 0 | i: 63900 |                         LR: 0.00020 |                         Loss Val: 510.533 | Loss Avg: 520.768\n",
      "Batch: 0 | i: 64000 |                         LR: 0.00019 |                         Loss Val: 510.527 | Loss Avg: 520.752\n",
      "Batch: 0 | i: 64100 |                         LR: 0.00019 |                         Loss Val: 510.515 | Loss Avg: 520.736\n",
      "Batch: 0 | i: 64200 |                         LR: 0.00019 |                         Loss Val: 510.505 | Loss Avg: 520.720\n",
      "Batch: 0 | i: 64300 |                         LR: 0.00019 |                         Loss Val: 510.497 | Loss Avg: 520.704\n",
      "Batch: 0 | i: 64400 |                         LR: 0.00019 |                         Loss Val: 510.491 | Loss Avg: 520.688\n",
      "Batch: 0 | i: 64500 |                         LR: 0.00019 |                         Loss Val: 510.480 | Loss Avg: 520.672\n",
      "Batch: 0 | i: 64600 |                         LR: 0.00019 |                         Loss Val: 510.474 | Loss Avg: 520.657\n",
      "Batch: 0 | i: 64700 |                         LR: 0.00019 |                         Loss Val: 510.476 | Loss Avg: 520.641\n",
      "Batch: 0 | i: 64800 |                         LR: 0.00019 |                         Loss Val: 510.461 | Loss Avg: 520.625\n",
      "Batch: 0 | i: 64900 |                         LR: 0.00019 |                         Loss Val: 510.452 | Loss Avg: 520.609\n",
      "Batch: 0 | i: 65000 |                         LR: 0.00019 |                         Loss Val: 510.442 | Loss Avg: 520.594\n",
      "Batch: 0 | i: 65100 |                         LR: 0.00019 |                         Loss Val: 510.440 | Loss Avg: 520.578\n",
      "Batch: 0 | i: 65200 |                         LR: 0.00019 |                         Loss Val: 510.431 | Loss Avg: 520.563\n",
      "Batch: 0 | i: 65300 |                         LR: 0.00019 |                         Loss Val: 510.424 | Loss Avg: 520.547\n",
      "Batch: 0 | i: 65400 |                         LR: 0.00019 |                         Loss Val: 510.423 | Loss Avg: 520.532\n",
      "Batch: 0 | i: 65500 |                         LR: 0.00019 |                         Loss Val: 510.418 | Loss Avg: 520.516\n",
      "Batch: 0 | i: 65600 |                         LR: 0.00019 |                         Loss Val: 510.413 | Loss Avg: 520.501\n",
      "Batch: 0 | i: 65700 |                         LR: 0.00019 |                         Loss Val: 510.407 | Loss Avg: 520.486\n",
      "Batch: 0 | i: 65800 |                         LR: 0.00019 |                         Loss Val: 510.400 | Loss Avg: 520.470\n",
      "Batch: 0 | i: 65900 |                         LR: 0.00019 |                         Loss Val: 510.390 | Loss Avg: 520.455\n",
      "Batch: 0 | i: 66000 |                         LR: 0.00018 |                         Loss Val: 510.390 | Loss Avg: 520.440\n",
      "Batch: 0 | i: 66100 |                         LR: 0.00018 |                         Loss Val: 510.381 | Loss Avg: 520.424\n",
      "Batch: 0 | i: 66200 |                         LR: 0.00018 |                         Loss Val: 510.375 | Loss Avg: 520.409\n",
      "Batch: 0 | i: 66300 |                         LR: 0.00018 |                         Loss Val: 510.378 | Loss Avg: 520.394\n",
      "Batch: 0 | i: 66400 |                         LR: 0.00018 |                         Loss Val: 510.374 | Loss Avg: 520.379\n",
      "Batch: 0 | i: 66500 |                         LR: 0.00018 |                         Loss Val: 510.368 | Loss Avg: 520.364\n",
      "Batch: 0 | i: 66600 |                         LR: 0.00018 |                         Loss Val: 510.368 | Loss Avg: 520.349\n",
      "Batch: 0 | i: 66700 |                         LR: 0.00018 |                         Loss Val: 510.363 | Loss Avg: 520.334\n",
      "Batch: 0 | i: 66800 |                         LR: 0.00018 |                         Loss Val: 510.355 | Loss Avg: 520.319\n",
      "Batch: 0 | i: 66900 |                         LR: 0.00018 |                         Loss Val: 510.354 | Loss Avg: 520.304\n",
      "Batch: 0 | i: 67000 |                         LR: 0.00018 |                         Loss Val: 510.349 | Loss Avg: 520.289\n",
      "Batch: 0 | i: 67100 |                         LR: 0.00018 |                         Loss Val: 510.343 | Loss Avg: 520.275\n",
      "Batch: 0 | i: 67200 |                         LR: 0.00018 |                         Loss Val: 510.337 | Loss Avg: 520.260\n",
      "Batch: 0 | i: 67300 |                         LR: 0.00018 |                         Loss Val: 510.338 | Loss Avg: 520.245\n",
      "Batch: 0 | i: 67400 |                         LR: 0.00018 |                         Loss Val: 510.337 | Loss Avg: 520.230\n",
      "Batch: 0 | i: 67500 |                         LR: 0.00018 |                         Loss Val: 510.338 | Loss Avg: 520.216\n",
      "Batch: 0 | i: 67600 |                         LR: 0.00018 |                         Loss Val: 510.333 | Loss Avg: 520.201\n",
      "Batch: 0 | i: 67700 |                         LR: 0.00018 |                         Loss Val: 510.332 | Loss Avg: 520.186\n",
      "Batch: 0 | i: 67800 |                         LR: 0.00018 |                         Loss Val: 510.326 | Loss Avg: 520.172\n",
      "Batch: 0 | i: 67900 |                         LR: 0.00018 |                         Loss Val: 510.320 | Loss Avg: 520.157\n",
      "Batch: 0 | i: 68000 |                         LR: 0.00017 |                         Loss Val: 510.317 | Loss Avg: 520.143\n",
      "Batch: 0 | i: 68100 |                         LR: 0.00017 |                         Loss Val: 510.314 | Loss Avg: 520.129\n",
      "Batch: 0 | i: 68200 |                         LR: 0.00017 |                         Loss Val: 510.318 | Loss Avg: 520.114\n",
      "Batch: 0 | i: 68300 |                         LR: 0.00017 |                         Loss Val: 510.312 | Loss Avg: 520.100\n",
      "Batch: 0 | i: 68400 |                         LR: 0.00017 |                         Loss Val: 510.309 | Loss Avg: 520.085\n",
      "Batch: 0 | i: 68500 |                         LR: 0.00017 |                         Loss Val: 510.311 | Loss Avg: 520.071\n",
      "Batch: 0 | i: 68600 |                         LR: 0.00017 |                         Loss Val: 510.301 | Loss Avg: 520.057\n",
      "Batch: 0 | i: 68700 |                         LR: 0.00017 |                         Loss Val: 510.300 | Loss Avg: 520.043\n",
      "Batch: 0 | i: 68800 |                         LR: 0.00017 |                         Loss Val: 510.300 | Loss Avg: 520.029\n",
      "Batch: 0 | i: 68900 |                         LR: 0.00017 |                         Loss Val: 510.302 | Loss Avg: 520.014\n",
      "Batch: 0 | i: 69000 |                         LR: 0.00017 |                         Loss Val: 510.298 | Loss Avg: 520.000\n",
      "Batch: 0 | i: 69100 |                         LR: 0.00017 |                         Loss Val: 510.290 | Loss Avg: 519.986\n",
      "Batch: 0 | i: 69200 |                         LR: 0.00017 |                         Loss Val: 510.287 | Loss Avg: 519.972\n",
      "Batch: 0 | i: 69300 |                         LR: 0.00017 |                         Loss Val: 510.288 | Loss Avg: 519.958\n",
      "Batch: 0 | i: 69400 |                         LR: 0.00017 |                         Loss Val: 510.291 | Loss Avg: 519.944\n",
      "Batch: 0 | i: 69500 |                         LR: 0.00017 |                         Loss Val: 510.281 | Loss Avg: 519.931\n",
      "Batch: 0 | i: 69600 |                         LR: 0.00017 |                         Loss Val: 510.281 | Loss Avg: 519.917\n",
      "Batch: 0 | i: 69700 |                         LR: 0.00017 |                         Loss Val: 510.275 | Loss Avg: 519.903\n",
      "Batch: 0 | i: 69800 |                         LR: 0.00017 |                         Loss Val: 510.272 | Loss Avg: 519.889\n",
      "Batch: 0 | i: 69900 |                         LR: 0.00017 |                         Loss Val: 510.278 | Loss Avg: 519.875\n",
      "Batch: 0 | i: 70000 |                         LR: 0.00017 |                         Loss Val: 510.267 | Loss Avg: 519.862\n",
      "Batch: 0 | i: 70100 |                         LR: 0.00017 |                         Loss Val: 510.267 | Loss Avg: 519.848\n",
      "Batch: 0 | i: 70200 |                         LR: 0.00017 |                         Loss Val: 510.264 | Loss Avg: 519.834\n",
      "Batch: 0 | i: 70300 |                         LR: 0.00017 |                         Loss Val: 510.263 | Loss Avg: 519.821\n",
      "Batch: 0 | i: 70400 |                         LR: 0.00017 |                         Loss Val: 510.256 | Loss Avg: 519.807\n",
      "Batch: 0 | i: 70500 |                         LR: 0.00017 |                         Loss Val: 510.260 | Loss Avg: 519.794\n",
      "Batch: 0 | i: 70600 |                         LR: 0.00017 |                         Loss Val: 510.267 | Loss Avg: 519.780\n",
      "Batch: 0 | i: 70700 |                         LR: 0.00017 |                         Loss Val: 510.255 | Loss Avg: 519.767\n",
      "Batch: 0 | i: 70800 |                         LR: 0.00017 |                         Loss Val: 510.252 | Loss Avg: 519.753\n",
      "Batch: 0 | i: 70900 |                         LR: 0.00017 |                         Loss Val: 510.250 | Loss Avg: 519.740\n",
      "Batch: 0 | i: 71000 |                         LR: 0.00017 |                         Loss Val: 510.249 | Loss Avg: 519.726\n",
      "Batch: 0 | i: 71100 |                         LR: 0.00017 |                         Loss Val: 510.241 | Loss Avg: 519.713\n",
      "Batch: 0 | i: 71200 |                         LR: 0.00017 |                         Loss Val: 510.242 | Loss Avg: 519.700\n",
      "Batch: 0 | i: 71300 |                         LR: 0.00017 |                         Loss Val: 510.246 | Loss Avg: 519.686\n",
      "Batch: 0 | i: 71400 |                         LR: 0.00017 |                         Loss Val: 510.244 | Loss Avg: 519.673\n",
      "Batch: 0 | i: 71500 |                         LR: 0.00017 |                         Loss Val: 510.243 | Loss Avg: 519.660\n",
      "Batch: 0 | i: 71600 |                         LR: 0.00017 |                         Loss Val: 510.241 | Loss Avg: 519.647\n",
      "Batch: 0 | i: 71700 |                         LR: 0.00017 |                         Loss Val: 510.233 | Loss Avg: 519.634\n",
      "Batch: 0 | i: 71800 |                         LR: 0.00017 |                         Loss Val: 510.233 | Loss Avg: 519.621\n",
      "Batch: 0 | i: 71900 |                         LR: 0.00017 |                         Loss Val: 510.235 | Loss Avg: 519.608\n",
      "Batch: 0 | i: 72000 |                         LR: 0.00016 |                         Loss Val: 510.228 | Loss Avg: 519.595\n",
      "Batch: 0 | i: 72100 |                         LR: 0.00016 |                         Loss Val: 510.227 | Loss Avg: 519.582\n",
      "Batch: 0 | i: 72200 |                         LR: 0.00016 |                         Loss Val: 510.231 | Loss Avg: 519.569\n",
      "Batch: 0 | i: 72300 |                         LR: 0.00016 |                         Loss Val: 510.225 | Loss Avg: 519.556\n",
      "Batch: 0 | i: 72400 |                         LR: 0.00016 |                         Loss Val: 510.230 | Loss Avg: 519.543\n",
      "Batch: 0 | i: 72500 |                         LR: 0.00016 |                         Loss Val: 510.224 | Loss Avg: 519.530\n",
      "Batch: 0 | i: 72600 |                         LR: 0.00016 |                         Loss Val: 510.221 | Loss Avg: 519.517\n",
      "Batch: 0 | i: 72700 |                         LR: 0.00016 |                         Loss Val: 510.219 | Loss Avg: 519.504\n",
      "Batch: 0 | i: 72800 |                         LR: 0.00016 |                         Loss Val: 510.224 | Loss Avg: 519.492\n",
      "Batch: 0 | i: 72900 |                         LR: 0.00016 |                         Loss Val: 510.224 | Loss Avg: 519.479\n",
      "Batch: 0 | i: 73000 |                         LR: 0.00016 |                         Loss Val: 510.221 | Loss Avg: 519.466\n",
      "Batch: 0 | i: 73100 |                         LR: 0.00016 |                         Loss Val: 510.212 | Loss Avg: 519.454\n",
      "Batch: 0 | i: 73200 |                         LR: 0.00016 |                         Loss Val: 510.210 | Loss Avg: 519.441\n",
      "Batch: 0 | i: 73300 |                         LR: 0.00016 |                         Loss Val: 510.213 | Loss Avg: 519.428\n",
      "Batch: 0 | i: 73400 |                         LR: 0.00016 |                         Loss Val: 510.209 | Loss Avg: 519.416\n",
      "Batch: 0 | i: 73500 |                         LR: 0.00016 |                         Loss Val: 510.208 | Loss Avg: 519.403\n",
      "Batch: 0 | i: 73600 |                         LR: 0.00016 |                         Loss Val: 510.207 | Loss Avg: 519.391\n",
      "Batch: 0 | i: 73700 |                         LR: 0.00016 |                         Loss Val: 510.208 | Loss Avg: 519.378\n",
      "Batch: 0 | i: 73800 |                         LR: 0.00016 |                         Loss Val: 510.203 | Loss Avg: 519.366\n",
      "Batch: 0 | i: 73900 |                         LR: 0.00016 |                         Loss Val: 510.202 | Loss Avg: 519.353\n",
      "Batch: 0 | i: 74000 |                         LR: 0.00015 |                         Loss Val: 510.204 | Loss Avg: 519.341\n",
      "Batch: 0 | i: 74100 |                         LR: 0.00015 |                         Loss Val: 510.204 | Loss Avg: 519.329\n",
      "Batch: 0 | i: 74200 |                         LR: 0.00015 |                         Loss Val: 510.202 | Loss Avg: 519.316\n",
      "Batch: 0 | i: 74300 |                         LR: 0.00015 |                         Loss Val: 510.201 | Loss Avg: 519.304\n",
      "Batch: 0 | i: 74400 |                         LR: 0.00015 |                         Loss Val: 510.197 | Loss Avg: 519.292\n",
      "Batch: 0 | i: 74500 |                         LR: 0.00015 |                         Loss Val: 510.197 | Loss Avg: 519.280\n",
      "Batch: 0 | i: 74600 |                         LR: 0.00015 |                         Loss Val: 510.197 | Loss Avg: 519.268\n",
      "Batch: 0 | i: 74700 |                         LR: 0.00015 |                         Loss Val: 510.192 | Loss Avg: 519.255\n",
      "Batch: 0 | i: 74800 |                         LR: 0.00015 |                         Loss Val: 510.190 | Loss Avg: 519.243\n",
      "Batch: 0 | i: 74900 |                         LR: 0.00015 |                         Loss Val: 510.193 | Loss Avg: 519.231\n",
      "Batch: 0 | i: 75000 |                         LR: 0.00015 |                         Loss Val: 510.192 | Loss Avg: 519.219\n",
      "Batch: 0 | i: 75100 |                         LR: 0.00015 |                         Loss Val: 510.196 | Loss Avg: 519.207\n",
      "Batch: 0 | i: 75200 |                         LR: 0.00015 |                         Loss Val: 510.187 | Loss Avg: 519.195\n",
      "Batch: 0 | i: 75300 |                         LR: 0.00015 |                         Loss Val: 510.190 | Loss Avg: 519.183\n",
      "Batch: 0 | i: 75400 |                         LR: 0.00015 |                         Loss Val: 510.184 | Loss Avg: 519.171\n",
      "Batch: 0 | i: 75500 |                         LR: 0.00015 |                         Loss Val: 510.184 | Loss Avg: 519.159\n",
      "Batch: 0 | i: 75600 |                         LR: 0.00015 |                         Loss Val: 510.182 | Loss Avg: 519.148\n",
      "Batch: 0 | i: 75700 |                         LR: 0.00015 |                         Loss Val: 510.182 | Loss Avg: 519.136\n",
      "Batch: 0 | i: 75800 |                         LR: 0.00015 |                         Loss Val: 510.180 | Loss Avg: 519.124\n",
      "Batch: 0 | i: 75900 |                         LR: 0.00015 |                         Loss Val: 510.182 | Loss Avg: 519.112\n",
      "Batch: 0 | i: 76000 |                         LR: 0.00014 |                         Loss Val: 510.179 | Loss Avg: 519.100\n",
      "Batch: 0 | i: 76100 |                         LR: 0.00014 |                         Loss Val: 510.177 | Loss Avg: 519.089\n",
      "Batch: 0 | i: 76200 |                         LR: 0.00014 |                         Loss Val: 510.176 | Loss Avg: 519.077\n",
      "Batch: 0 | i: 76300 |                         LR: 0.00014 |                         Loss Val: 510.174 | Loss Avg: 519.065\n",
      "Batch: 0 | i: 76400 |                         LR: 0.00014 |                         Loss Val: 510.176 | Loss Avg: 519.054\n",
      "Batch: 0 | i: 76500 |                         LR: 0.00014 |                         Loss Val: 510.174 | Loss Avg: 519.042\n",
      "Batch: 0 | i: 76600 |                         LR: 0.00014 |                         Loss Val: 510.173 | Loss Avg: 519.030\n",
      "Batch: 0 | i: 76700 |                         LR: 0.00014 |                         Loss Val: 510.173 | Loss Avg: 519.019\n",
      "Batch: 0 | i: 76800 |                         LR: 0.00014 |                         Loss Val: 510.170 | Loss Avg: 519.007\n",
      "Batch: 0 | i: 76900 |                         LR: 0.00014 |                         Loss Val: 510.173 | Loss Avg: 518.996\n",
      "Batch: 0 | i: 77000 |                         LR: 0.00014 |                         Loss Val: 510.171 | Loss Avg: 518.984\n",
      "Batch: 0 | i: 77100 |                         LR: 0.00014 |                         Loss Val: 510.167 | Loss Avg: 518.973\n",
      "Batch: 0 | i: 77200 |                         LR: 0.00014 |                         Loss Val: 510.167 | Loss Avg: 518.962\n",
      "Batch: 0 | i: 77300 |                         LR: 0.00014 |                         Loss Val: 510.163 | Loss Avg: 518.950\n",
      "Batch: 0 | i: 77400 |                         LR: 0.00014 |                         Loss Val: 510.162 | Loss Avg: 518.939\n",
      "Batch: 0 | i: 77500 |                         LR: 0.00014 |                         Loss Val: 510.163 | Loss Avg: 518.928\n",
      "Batch: 0 | i: 77600 |                         LR: 0.00014 |                         Loss Val: 510.162 | Loss Avg: 518.916\n",
      "Batch: 0 | i: 77700 |                         LR: 0.00014 |                         Loss Val: 510.160 | Loss Avg: 518.905\n",
      "Batch: 0 | i: 77800 |                         LR: 0.00014 |                         Loss Val: 510.161 | Loss Avg: 518.894\n",
      "Batch: 0 | i: 77900 |                         LR: 0.00014 |                         Loss Val: 510.163 | Loss Avg: 518.883\n",
      "Batch: 0 | i: 78000 |                         LR: 0.00014 |                         Loss Val: 510.158 | Loss Avg: 518.871\n",
      "Batch: 0 | i: 78100 |                         LR: 0.00014 |                         Loss Val: 510.154 | Loss Avg: 518.860\n",
      "Batch: 0 | i: 78200 |                         LR: 0.00014 |                         Loss Val: 510.158 | Loss Avg: 518.849\n",
      "Batch: 0 | i: 78300 |                         LR: 0.00014 |                         Loss Val: 510.154 | Loss Avg: 518.838\n",
      "Batch: 0 | i: 78400 |                         LR: 0.00014 |                         Loss Val: 510.154 | Loss Avg: 518.827\n",
      "Batch: 0 | i: 78500 |                         LR: 0.00014 |                         Loss Val: 510.150 | Loss Avg: 518.816\n",
      "Batch: 0 | i: 78600 |                         LR: 0.00014 |                         Loss Val: 510.150 | Loss Avg: 518.805\n",
      "Batch: 0 | i: 78700 |                         LR: 0.00014 |                         Loss Val: 510.151 | Loss Avg: 518.794\n",
      "Batch: 0 | i: 78800 |                         LR: 0.00014 |                         Loss Val: 510.148 | Loss Avg: 518.783\n",
      "Batch: 0 | i: 78900 |                         LR: 0.00014 |                         Loss Val: 510.149 | Loss Avg: 518.772\n",
      "Batch: 0 | i: 79000 |                         LR: 0.00014 |                         Loss Val: 510.146 | Loss Avg: 518.761\n",
      "Batch: 0 | i: 79100 |                         LR: 0.00014 |                         Loss Val: 510.146 | Loss Avg: 518.750\n",
      "Batch: 0 | i: 79200 |                         LR: 0.00014 |                         Loss Val: 510.149 | Loss Avg: 518.739\n",
      "Batch: 0 | i: 79300 |                         LR: 0.00014 |                         Loss Val: 510.145 | Loss Avg: 518.728\n",
      "Batch: 0 | i: 79400 |                         LR: 0.00014 |                         Loss Val: 510.143 | Loss Avg: 518.718\n",
      "Batch: 0 | i: 79500 |                         LR: 0.00014 |                         Loss Val: 510.145 | Loss Avg: 518.707\n",
      "Batch: 0 | i: 79600 |                         LR: 0.00014 |                         Loss Val: 510.137 | Loss Avg: 518.696\n",
      "Batch: 0 | i: 79700 |                         LR: 0.00014 |                         Loss Val: 510.140 | Loss Avg: 518.685\n",
      "Batch: 0 | i: 79800 |                         LR: 0.00014 |                         Loss Val: 510.139 | Loss Avg: 518.675\n",
      "Batch: 0 | i: 79900 |                         LR: 0.00014 |                         Loss Val: 510.137 | Loss Avg: 518.664\n",
      "Batch: 0 | i: 80000 |                         LR: 0.00013 |                         Loss Val: 510.135 | Loss Avg: 518.653\n",
      "Batch: 0 | i: 80100 |                         LR: 0.00013 |                         Loss Val: 510.138 | Loss Avg: 518.643\n",
      "Batch: 0 | i: 80200 |                         LR: 0.00013 |                         Loss Val: 510.134 | Loss Avg: 518.632\n",
      "Batch: 0 | i: 80300 |                         LR: 0.00013 |                         Loss Val: 510.134 | Loss Avg: 518.621\n",
      "Batch: 0 | i: 80400 |                         LR: 0.00013 |                         Loss Val: 510.132 | Loss Avg: 518.611\n",
      "Batch: 0 | i: 80500 |                         LR: 0.00013 |                         Loss Val: 510.131 | Loss Avg: 518.600\n",
      "Batch: 0 | i: 80600 |                         LR: 0.00013 |                         Loss Val: 510.133 | Loss Avg: 518.590\n",
      "Batch: 0 | i: 80700 |                         LR: 0.00013 |                         Loss Val: 510.129 | Loss Avg: 518.579\n",
      "Batch: 0 | i: 80800 |                         LR: 0.00013 |                         Loss Val: 510.128 | Loss Avg: 518.569\n",
      "Batch: 0 | i: 80900 |                         LR: 0.00013 |                         Loss Val: 510.128 | Loss Avg: 518.558\n",
      "Batch: 0 | i: 81000 |                         LR: 0.00013 |                         Loss Val: 510.127 | Loss Avg: 518.548\n",
      "Batch: 0 | i: 81100 |                         LR: 0.00013 |                         Loss Val: 510.126 | Loss Avg: 518.538\n",
      "Batch: 0 | i: 81200 |                         LR: 0.00013 |                         Loss Val: 510.124 | Loss Avg: 518.527\n",
      "Batch: 0 | i: 81300 |                         LR: 0.00013 |                         Loss Val: 510.126 | Loss Avg: 518.517\n",
      "Batch: 0 | i: 81400 |                         LR: 0.00013 |                         Loss Val: 510.125 | Loss Avg: 518.507\n",
      "Batch: 0 | i: 81500 |                         LR: 0.00013 |                         Loss Val: 510.123 | Loss Avg: 518.496\n",
      "Batch: 0 | i: 81600 |                         LR: 0.00013 |                         Loss Val: 510.125 | Loss Avg: 518.486\n",
      "Batch: 0 | i: 81700 |                         LR: 0.00013 |                         Loss Val: 510.123 | Loss Avg: 518.476\n",
      "Batch: 0 | i: 81800 |                         LR: 0.00013 |                         Loss Val: 510.118 | Loss Avg: 518.466\n",
      "Batch: 0 | i: 81900 |                         LR: 0.00013 |                         Loss Val: 510.123 | Loss Avg: 518.456\n",
      "Batch: 0 | i: 82000 |                         LR: 0.00012 |                         Loss Val: 510.119 | Loss Avg: 518.445\n",
      "Batch: 0 | i: 82100 |                         LR: 0.00012 |                         Loss Val: 510.118 | Loss Avg: 518.435\n",
      "Batch: 0 | i: 82200 |                         LR: 0.00012 |                         Loss Val: 510.116 | Loss Avg: 518.425\n",
      "Batch: 0 | i: 82300 |                         LR: 0.00012 |                         Loss Val: 510.119 | Loss Avg: 518.415\n",
      "Batch: 0 | i: 82400 |                         LR: 0.00012 |                         Loss Val: 510.114 | Loss Avg: 518.405\n",
      "Batch: 0 | i: 82500 |                         LR: 0.00012 |                         Loss Val: 510.112 | Loss Avg: 518.395\n",
      "Batch: 0 | i: 82600 |                         LR: 0.00012 |                         Loss Val: 510.113 | Loss Avg: 518.385\n",
      "Batch: 0 | i: 82700 |                         LR: 0.00012 |                         Loss Val: 510.112 | Loss Avg: 518.375\n",
      "Batch: 0 | i: 82800 |                         LR: 0.00012 |                         Loss Val: 510.111 | Loss Avg: 518.365\n",
      "Batch: 0 | i: 82900 |                         LR: 0.00012 |                         Loss Val: 510.112 | Loss Avg: 518.355\n",
      "Batch: 0 | i: 83000 |                         LR: 0.00012 |                         Loss Val: 510.111 | Loss Avg: 518.345\n",
      "Batch: 0 | i: 83100 |                         LR: 0.00012 |                         Loss Val: 510.111 | Loss Avg: 518.335\n",
      "Batch: 0 | i: 83200 |                         LR: 0.00012 |                         Loss Val: 510.112 | Loss Avg: 518.325\n",
      "Batch: 0 | i: 83300 |                         LR: 0.00012 |                         Loss Val: 510.109 | Loss Avg: 518.315\n",
      "Batch: 0 | i: 83400 |                         LR: 0.00012 |                         Loss Val: 510.106 | Loss Avg: 518.305\n",
      "Batch: 0 | i: 83500 |                         LR: 0.00012 |                         Loss Val: 510.104 | Loss Avg: 518.296\n",
      "Batch: 0 | i: 83600 |                         LR: 0.00012 |                         Loss Val: 510.105 | Loss Avg: 518.286\n",
      "Batch: 0 | i: 83700 |                         LR: 0.00012 |                         Loss Val: 510.105 | Loss Avg: 518.276\n",
      "Batch: 0 | i: 83800 |                         LR: 0.00012 |                         Loss Val: 510.101 | Loss Avg: 518.266\n",
      "Batch: 0 | i: 83900 |                         LR: 0.00012 |                         Loss Val: 510.100 | Loss Avg: 518.257\n",
      "Batch: 0 | i: 84000 |                         LR: 0.00012 |                         Loss Val: 510.100 | Loss Avg: 518.247\n",
      "Batch: 0 | i: 84100 |                         LR: 0.00012 |                         Loss Val: 510.099 | Loss Avg: 518.237\n",
      "Batch: 0 | i: 84200 |                         LR: 0.00012 |                         Loss Val: 510.098 | Loss Avg: 518.228\n",
      "Batch: 0 | i: 84300 |                         LR: 0.00012 |                         Loss Val: 510.100 | Loss Avg: 518.218\n",
      "Batch: 0 | i: 84400 |                         LR: 0.00012 |                         Loss Val: 510.097 | Loss Avg: 518.208\n",
      "Batch: 0 | i: 84500 |                         LR: 0.00012 |                         Loss Val: 510.097 | Loss Avg: 518.199\n",
      "Batch: 0 | i: 84600 |                         LR: 0.00012 |                         Loss Val: 510.096 | Loss Avg: 518.189\n",
      "Batch: 0 | i: 84700 |                         LR: 0.00012 |                         Loss Val: 510.093 | Loss Avg: 518.180\n",
      "Batch: 0 | i: 84800 |                         LR: 0.00012 |                         Loss Val: 510.093 | Loss Avg: 518.170\n",
      "Batch: 0 | i: 84900 |                         LR: 0.00012 |                         Loss Val: 510.093 | Loss Avg: 518.160\n",
      "Batch: 0 | i: 85000 |                         LR: 0.00012 |                         Loss Val: 510.093 | Loss Avg: 518.151\n",
      "Batch: 0 | i: 85100 |                         LR: 0.00012 |                         Loss Val: 510.093 | Loss Avg: 518.142\n",
      "Batch: 0 | i: 85200 |                         LR: 0.00012 |                         Loss Val: 510.091 | Loss Avg: 518.132\n",
      "Batch: 0 | i: 85300 |                         LR: 0.00012 |                         Loss Val: 510.092 | Loss Avg: 518.123\n",
      "Batch: 0 | i: 85400 |                         LR: 0.00012 |                         Loss Val: 510.088 | Loss Avg: 518.113\n",
      "Batch: 0 | i: 85500 |                         LR: 0.00012 |                         Loss Val: 510.089 | Loss Avg: 518.104\n",
      "Batch: 0 | i: 85600 |                         LR: 0.00012 |                         Loss Val: 510.086 | Loss Avg: 518.095\n",
      "Batch: 0 | i: 85700 |                         LR: 0.00012 |                         Loss Val: 510.089 | Loss Avg: 518.085\n",
      "Batch: 0 | i: 85800 |                         LR: 0.00012 |                         Loss Val: 510.088 | Loss Avg: 518.076\n",
      "Batch: 0 | i: 85900 |                         LR: 0.00012 |                         Loss Val: 510.088 | Loss Avg: 518.067\n",
      "Batch: 0 | i: 86000 |                         LR: 0.00011 |                         Loss Val: 510.088 | Loss Avg: 518.057\n",
      "Batch: 0 | i: 86100 |                         LR: 0.00011 |                         Loss Val: 510.084 | Loss Avg: 518.048\n",
      "Batch: 0 | i: 86200 |                         LR: 0.00011 |                         Loss Val: 510.086 | Loss Avg: 518.039\n",
      "Batch: 0 | i: 86300 |                         LR: 0.00011 |                         Loss Val: 510.085 | Loss Avg: 518.030\n",
      "Batch: 0 | i: 86400 |                         LR: 0.00011 |                         Loss Val: 510.081 | Loss Avg: 518.020\n",
      "Batch: 0 | i: 86500 |                         LR: 0.00011 |                         Loss Val: 510.084 | Loss Avg: 518.011\n",
      "Batch: 0 | i: 86600 |                         LR: 0.00011 |                         Loss Val: 510.084 | Loss Avg: 518.002\n",
      "Batch: 0 | i: 86700 |                         LR: 0.00011 |                         Loss Val: 510.080 | Loss Avg: 517.993\n",
      "Batch: 0 | i: 86800 |                         LR: 0.00011 |                         Loss Val: 510.082 | Loss Avg: 517.984\n",
      "Batch: 0 | i: 86900 |                         LR: 0.00011 |                         Loss Val: 510.080 | Loss Avg: 517.975\n",
      "Batch: 0 | i: 87000 |                         LR: 0.00011 |                         Loss Val: 510.076 | Loss Avg: 517.966\n",
      "Batch: 0 | i: 87100 |                         LR: 0.00011 |                         Loss Val: 510.080 | Loss Avg: 517.957\n",
      "Batch: 0 | i: 87200 |                         LR: 0.00011 |                         Loss Val: 510.078 | Loss Avg: 517.948\n",
      "Batch: 0 | i: 87300 |                         LR: 0.00011 |                         Loss Val: 510.075 | Loss Avg: 517.938\n",
      "Batch: 0 | i: 87400 |                         LR: 0.00011 |                         Loss Val: 510.076 | Loss Avg: 517.930\n",
      "Batch: 0 | i: 87500 |                         LR: 0.00011 |                         Loss Val: 510.073 | Loss Avg: 517.921\n",
      "Batch: 0 | i: 87600 |                         LR: 0.00011 |                         Loss Val: 510.073 | Loss Avg: 517.912\n",
      "Batch: 0 | i: 87700 |                         LR: 0.00011 |                         Loss Val: 510.077 | Loss Avg: 517.903\n",
      "Batch: 0 | i: 87800 |                         LR: 0.00011 |                         Loss Val: 510.073 | Loss Avg: 517.894\n",
      "Batch: 0 | i: 87900 |                         LR: 0.00011 |                         Loss Val: 510.071 | Loss Avg: 517.885\n",
      "Batch: 0 | i: 88000 |                         LR: 0.00010 |                         Loss Val: 510.070 | Loss Avg: 517.876\n",
      "Batch: 0 | i: 88100 |                         LR: 0.00010 |                         Loss Val: 510.071 | Loss Avg: 517.867\n",
      "Batch: 0 | i: 88200 |                         LR: 0.00010 |                         Loss Val: 510.072 | Loss Avg: 517.858\n",
      "Batch: 0 | i: 88300 |                         LR: 0.00010 |                         Loss Val: 510.073 | Loss Avg: 517.849\n",
      "Batch: 0 | i: 88400 |                         LR: 0.00010 |                         Loss Val: 510.071 | Loss Avg: 517.841\n",
      "Batch: 0 | i: 88500 |                         LR: 0.00010 |                         Loss Val: 510.070 | Loss Avg: 517.832\n",
      "Batch: 0 | i: 88600 |                         LR: 0.00010 |                         Loss Val: 510.068 | Loss Avg: 517.823\n",
      "Batch: 0 | i: 88700 |                         LR: 0.00010 |                         Loss Val: 510.067 | Loss Avg: 517.814\n",
      "Batch: 0 | i: 88800 |                         LR: 0.00010 |                         Loss Val: 510.068 | Loss Avg: 517.806\n",
      "Batch: 0 | i: 88900 |                         LR: 0.00010 |                         Loss Val: 510.066 | Loss Avg: 517.797\n",
      "Batch: 0 | i: 89000 |                         LR: 0.00010 |                         Loss Val: 510.066 | Loss Avg: 517.788\n",
      "Batch: 0 | i: 89100 |                         LR: 0.00010 |                         Loss Val: 510.065 | Loss Avg: 517.780\n",
      "Batch: 0 | i: 89200 |                         LR: 0.00010 |                         Loss Val: 510.068 | Loss Avg: 517.771\n",
      "Batch: 0 | i: 89300 |                         LR: 0.00010 |                         Loss Val: 510.063 | Loss Avg: 517.762\n",
      "Batch: 0 | i: 89400 |                         LR: 0.00010 |                         Loss Val: 510.066 | Loss Avg: 517.754\n",
      "Batch: 0 | i: 89500 |                         LR: 0.00010 |                         Loss Val: 510.065 | Loss Avg: 517.745\n",
      "Batch: 0 | i: 89600 |                         LR: 0.00010 |                         Loss Val: 510.064 | Loss Avg: 517.737\n",
      "Batch: 0 | i: 89700 |                         LR: 0.00010 |                         Loss Val: 510.065 | Loss Avg: 517.728\n",
      "Batch: 0 | i: 89800 |                         LR: 0.00010 |                         Loss Val: 510.061 | Loss Avg: 517.719\n",
      "Batch: 0 | i: 89900 |                         LR: 0.00010 |                         Loss Val: 510.062 | Loss Avg: 517.711\n",
      "Batch: 0 | i: 90000 |                         LR: 0.00010 |                         Loss Val: 510.064 | Loss Avg: 517.702\n",
      "Batch: 0 | i: 90100 |                         LR: 0.00010 |                         Loss Val: 510.068 | Loss Avg: 517.694\n",
      "Batch: 0 | i: 90200 |                         LR: 0.00010 |                         Loss Val: 510.060 | Loss Avg: 517.685\n",
      "Batch: 0 | i: 90300 |                         LR: 0.00010 |                         Loss Val: 510.061 | Loss Avg: 517.677\n",
      "Batch: 0 | i: 90400 |                         LR: 0.00010 |                         Loss Val: 510.060 | Loss Avg: 517.669\n",
      "Batch: 0 | i: 90500 |                         LR: 0.00010 |                         Loss Val: 510.061 | Loss Avg: 517.660\n",
      "Batch: 0 | i: 90600 |                         LR: 0.00010 |                         Loss Val: 510.061 | Loss Avg: 517.652\n",
      "Batch: 0 | i: 90700 |                         LR: 0.00010 |                         Loss Val: 510.063 | Loss Avg: 517.643\n",
      "Batch: 0 | i: 90800 |                         LR: 0.00010 |                         Loss Val: 510.057 | Loss Avg: 517.635\n",
      "Batch: 0 | i: 90900 |                         LR: 0.00010 |                         Loss Val: 510.058 | Loss Avg: 517.627\n",
      "Batch: 0 | i: 91000 |                         LR: 0.00010 |                         Loss Val: 510.057 | Loss Avg: 517.618\n",
      "Batch: 0 | i: 91100 |                         LR: 0.00010 |                         Loss Val: 510.058 | Loss Avg: 517.610\n",
      "Batch: 0 | i: 91200 |                         LR: 0.00010 |                         Loss Val: 510.056 | Loss Avg: 517.602\n",
      "Batch: 0 | i: 91300 |                         LR: 0.00010 |                         Loss Val: 510.059 | Loss Avg: 517.594\n",
      "Batch: 0 | i: 91400 |                         LR: 0.00010 |                         Loss Val: 510.059 | Loss Avg: 517.585\n",
      "Batch: 0 | i: 91500 |                         LR: 0.00010 |                         Loss Val: 510.058 | Loss Avg: 517.577\n",
      "Batch: 0 | i: 91600 |                         LR: 0.00010 |                         Loss Val: 510.057 | Loss Avg: 517.569\n",
      "Batch: 0 | i: 91700 |                         LR: 0.00010 |                         Loss Val: 510.058 | Loss Avg: 517.561\n",
      "Batch: 0 | i: 91800 |                         LR: 0.00010 |                         Loss Val: 510.056 | Loss Avg: 517.553\n",
      "Batch: 0 | i: 91900 |                         LR: 0.00010 |                         Loss Val: 510.058 | Loss Avg: 517.544\n",
      "Batch: 0 | i: 92000 |                         LR: 0.00009 |                         Loss Val: 510.054 | Loss Avg: 517.536\n",
      "Batch: 0 | i: 92100 |                         LR: 0.00009 |                         Loss Val: 510.052 | Loss Avg: 517.528\n",
      "Batch: 0 | i: 92200 |                         LR: 0.00009 |                         Loss Val: 510.052 | Loss Avg: 517.520\n",
      "Batch: 0 | i: 92300 |                         LR: 0.00009 |                         Loss Val: 510.055 | Loss Avg: 517.512\n",
      "Batch: 0 | i: 92400 |                         LR: 0.00009 |                         Loss Val: 510.052 | Loss Avg: 517.504\n",
      "Batch: 0 | i: 92500 |                         LR: 0.00009 |                         Loss Val: 510.052 | Loss Avg: 517.496\n",
      "Batch: 0 | i: 92600 |                         LR: 0.00009 |                         Loss Val: 510.052 | Loss Avg: 517.488\n",
      "Batch: 0 | i: 92700 |                         LR: 0.00009 |                         Loss Val: 510.052 | Loss Avg: 517.480\n",
      "Batch: 0 | i: 92800 |                         LR: 0.00009 |                         Loss Val: 510.049 | Loss Avg: 517.472\n",
      "Batch: 0 | i: 92900 |                         LR: 0.00009 |                         Loss Val: 510.049 | Loss Avg: 517.464\n",
      "Batch: 0 | i: 93000 |                         LR: 0.00009 |                         Loss Val: 510.053 | Loss Avg: 517.456\n",
      "Batch: 0 | i: 93100 |                         LR: 0.00009 |                         Loss Val: 510.049 | Loss Avg: 517.448\n",
      "Batch: 0 | i: 93200 |                         LR: 0.00009 |                         Loss Val: 510.054 | Loss Avg: 517.440\n",
      "Batch: 0 | i: 93300 |                         LR: 0.00009 |                         Loss Val: 510.056 | Loss Avg: 517.432\n",
      "Batch: 0 | i: 93400 |                         LR: 0.00009 |                         Loss Val: 510.049 | Loss Avg: 517.424\n",
      "Batch: 0 | i: 93500 |                         LR: 0.00009 |                         Loss Val: 510.051 | Loss Avg: 517.416\n",
      "Batch: 0 | i: 93600 |                         LR: 0.00009 |                         Loss Val: 510.048 | Loss Avg: 517.408\n",
      "Batch: 0 | i: 93700 |                         LR: 0.00009 |                         Loss Val: 510.051 | Loss Avg: 517.400\n",
      "Batch: 0 | i: 93800 |                         LR: 0.00009 |                         Loss Val: 510.048 | Loss Avg: 517.393\n",
      "Batch: 0 | i: 93900 |                         LR: 0.00009 |                         Loss Val: 510.045 | Loss Avg: 517.385\n",
      "Batch: 0 | i: 94000 |                         LR: 0.00009 |                         Loss Val: 510.052 | Loss Avg: 517.377\n",
      "Batch: 0 | i: 94100 |                         LR: 0.00009 |                         Loss Val: 510.047 | Loss Avg: 517.369\n",
      "Batch: 0 | i: 94200 |                         LR: 0.00009 |                         Loss Val: 510.046 | Loss Avg: 517.361\n",
      "Batch: 0 | i: 94300 |                         LR: 0.00009 |                         Loss Val: 510.045 | Loss Avg: 517.354\n",
      "Batch: 0 | i: 94400 |                         LR: 0.00009 |                         Loss Val: 510.049 | Loss Avg: 517.346\n",
      "Batch: 0 | i: 94500 |                         LR: 0.00009 |                         Loss Val: 510.046 | Loss Avg: 517.338\n",
      "Batch: 0 | i: 94600 |                         LR: 0.00009 |                         Loss Val: 510.047 | Loss Avg: 517.331\n",
      "Batch: 0 | i: 94700 |                         LR: 0.00009 |                         Loss Val: 510.048 | Loss Avg: 517.323\n",
      "Batch: 0 | i: 94800 |                         LR: 0.00009 |                         Loss Val: 510.044 | Loss Avg: 517.315\n",
      "Batch: 0 | i: 94900 |                         LR: 0.00009 |                         Loss Val: 510.043 | Loss Avg: 517.307\n",
      "Batch: 0 | i: 95000 |                         LR: 0.00009 |                         Loss Val: 510.043 | Loss Avg: 517.300\n",
      "Batch: 0 | i: 95100 |                         LR: 0.00009 |                         Loss Val: 510.045 | Loss Avg: 517.292\n",
      "Batch: 0 | i: 95200 |                         LR: 0.00009 |                         Loss Val: 510.043 | Loss Avg: 517.285\n",
      "Batch: 0 | i: 95300 |                         LR: 0.00009 |                         Loss Val: 510.046 | Loss Avg: 517.277\n",
      "Batch: 0 | i: 95400 |                         LR: 0.00009 |                         Loss Val: 510.045 | Loss Avg: 517.269\n",
      "Batch: 0 | i: 95500 |                         LR: 0.00009 |                         Loss Val: 510.045 | Loss Avg: 517.262\n",
      "Batch: 0 | i: 95600 |                         LR: 0.00009 |                         Loss Val: 510.043 | Loss Avg: 517.254\n",
      "Batch: 0 | i: 95700 |                         LR: 0.00009 |                         Loss Val: 510.047 | Loss Avg: 517.247\n",
      "Batch: 0 | i: 95800 |                         LR: 0.00009 |                         Loss Val: 510.042 | Loss Avg: 517.239\n",
      "Batch: 0 | i: 95900 |                         LR: 0.00009 |                         Loss Val: 510.038 | Loss Avg: 517.232\n",
      "Batch: 0 | i: 96000 |                         LR: 0.00009 |                         Loss Val: 510.041 | Loss Avg: 517.224\n",
      "Batch: 0 | i: 96100 |                         LR: 0.00009 |                         Loss Val: 510.039 | Loss Avg: 517.217\n",
      "Batch: 0 | i: 96200 |                         LR: 0.00009 |                         Loss Val: 510.041 | Loss Avg: 517.209\n",
      "Batch: 0 | i: 96300 |                         LR: 0.00009 |                         Loss Val: 510.040 | Loss Avg: 517.202\n",
      "Batch: 0 | i: 96400 |                         LR: 0.00009 |                         Loss Val: 510.039 | Loss Avg: 517.194\n",
      "Batch: 0 | i: 96500 |                         LR: 0.00009 |                         Loss Val: 510.039 | Loss Avg: 517.187\n",
      "Batch: 0 | i: 96600 |                         LR: 0.00009 |                         Loss Val: 510.039 | Loss Avg: 517.180\n",
      "Batch: 0 | i: 96700 |                         LR: 0.00009 |                         Loss Val: 510.038 | Loss Avg: 517.172\n",
      "Batch: 0 | i: 96800 |                         LR: 0.00009 |                         Loss Val: 510.037 | Loss Avg: 517.165\n",
      "Batch: 0 | i: 96900 |                         LR: 0.00009 |                         Loss Val: 510.041 | Loss Avg: 517.158\n",
      "Batch: 0 | i: 97000 |                         LR: 0.00009 |                         Loss Val: 510.038 | Loss Avg: 517.150\n",
      "Batch: 0 | i: 97100 |                         LR: 0.00009 |                         Loss Val: 510.039 | Loss Avg: 517.143\n",
      "Batch: 0 | i: 97200 |                         LR: 0.00009 |                         Loss Val: 510.038 | Loss Avg: 517.136\n",
      "Batch: 0 | i: 97300 |                         LR: 0.00009 |                         Loss Val: 510.039 | Loss Avg: 517.128\n",
      "Batch: 0 | i: 97400 |                         LR: 0.00009 |                         Loss Val: 510.037 | Loss Avg: 517.121\n",
      "Batch: 0 | i: 97500 |                         LR: 0.00009 |                         Loss Val: 510.038 | Loss Avg: 517.114\n",
      "Batch: 0 | i: 97600 |                         LR: 0.00009 |                         Loss Val: 510.033 | Loss Avg: 517.106\n",
      "Batch: 0 | i: 97700 |                         LR: 0.00009 |                         Loss Val: 510.034 | Loss Avg: 517.099\n",
      "Batch: 0 | i: 97800 |                         LR: 0.00009 |                         Loss Val: 510.037 | Loss Avg: 517.092\n",
      "Batch: 0 | i: 97900 |                         LR: 0.00009 |                         Loss Val: 510.033 | Loss Avg: 517.085\n",
      "Batch: 0 | i: 98000 |                         LR: 0.00008 |                         Loss Val: 510.035 | Loss Avg: 517.078\n",
      "Batch: 0 | i: 98100 |                         LR: 0.00008 |                         Loss Val: 510.035 | Loss Avg: 517.070\n",
      "Batch: 0 | i: 98200 |                         LR: 0.00008 |                         Loss Val: 510.034 | Loss Avg: 517.063\n",
      "Batch: 0 | i: 98300 |                         LR: 0.00008 |                         Loss Val: 510.033 | Loss Avg: 517.056\n",
      "Batch: 0 | i: 98400 |                         LR: 0.00008 |                         Loss Val: 510.034 | Loss Avg: 517.049\n",
      "Batch: 0 | i: 98500 |                         LR: 0.00008 |                         Loss Val: 510.033 | Loss Avg: 517.042\n",
      "Batch: 0 | i: 98600 |                         LR: 0.00008 |                         Loss Val: 510.033 | Loss Avg: 517.035\n",
      "Batch: 0 | i: 98700 |                         LR: 0.00008 |                         Loss Val: 510.035 | Loss Avg: 517.028\n",
      "Batch: 0 | i: 98800 |                         LR: 0.00008 |                         Loss Val: 510.033 | Loss Avg: 517.021\n",
      "Batch: 0 | i: 98900 |                         LR: 0.00008 |                         Loss Val: 510.036 | Loss Avg: 517.013\n",
      "Batch: 0 | i: 99000 |                         LR: 0.00008 |                         Loss Val: 510.034 | Loss Avg: 517.006\n",
      "Batch: 0 | i: 99100 |                         LR: 0.00008 |                         Loss Val: 510.031 | Loss Avg: 516.999\n",
      "Batch: 0 | i: 99200 |                         LR: 0.00008 |                         Loss Val: 510.033 | Loss Avg: 516.992\n",
      "Batch: 0 | i: 99300 |                         LR: 0.00008 |                         Loss Val: 510.032 | Loss Avg: 516.985\n",
      "Batch: 0 | i: 99400 |                         LR: 0.00008 |                         Loss Val: 510.032 | Loss Avg: 516.978\n",
      "Batch: 0 | i: 99500 |                         LR: 0.00008 |                         Loss Val: 510.032 | Loss Avg: 516.971\n",
      "Batch: 0 | i: 99600 |                         LR: 0.00008 |                         Loss Val: 510.031 | Loss Avg: 516.964\n",
      "Batch: 0 | i: 99700 |                         LR: 0.00008 |                         Loss Val: 510.031 | Loss Avg: 516.957\n",
      "Batch: 0 | i: 99800 |                         LR: 0.00008 |                         Loss Val: 510.031 | Loss Avg: 516.951\n",
      "Batch: 0 | i: 99900 |                         LR: 0.00008 |                         Loss Val: 510.029 | Loss Avg: 516.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hidden Trigger: 100%|| 1/1 [26:18<00:00, 1578.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_Loss: 510.0285949707031\n",
      "Number of poison samples generated: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=2e-4)\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    clip_values=(min_, max_),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    "    preprocessing=(mean_, std_)\n",
    ")\n",
    "\n",
    "target = np.array([0,0,0,1,0,0,0,0,0,0])\n",
    "source = np.array([0,0,0,0,0,0,0,0,1,0])\n",
    "\n",
    "# Backdoor Trigger Parameters\n",
    "patch_size = 25\n",
    "x_shift = 28 - patch_size \n",
    "y_shift = 28 - patch_size \n",
    "\n",
    "# Define the backdoor poisoning object. Calling backdoor.poison(x) will insert the trigger into x.\n",
    "def mod(x):\n",
    "    original_dtype = x.dtype\n",
    "    x = insert_image(x, backdoor_path=\"./devil.png\",\n",
    "                                   channels_first=True, random=False, x_shift=x_shift, y_shift=y_shift,\n",
    "                                   size=(patch_size,patch_size), mode='L', blend=0.8)\n",
    "    return x.astype(original_dtype)\n",
    "backdoor = PoisoningAttackBackdoor(mod)\n",
    "\n",
    "poison_attack = HiddenTriggerBackdoor(classifier, eps=0.35, target=target, source=source, \n",
    "                                      feature_layer=4, backdoor=backdoor, decay_coeff = .95, \n",
    "                                      decay_iter = 2000, max_iter=100000, batch_size=64, poison_percent=0.80,\n",
    "                                      stopping_threshold=0.01)\n",
    "\n",
    "poison_data, poison_indices = poison_attack.poison(x_train, y_train.numpy()) # torch.argmax(loaded_labels, axis = 1), np.argmax(y_train, axis = 1)\n",
    "print(\"Number of poison samples generated:\", len(poison_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Filter Poisoned Images:\n",
    "\n",
    "* Retain only the poisoned images that are classified as the target (source) label by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17, 1, 28, 28), (17,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter successful poisioned data\n",
    "def filtered_poisoned_results(poison_data_predictions, poison_indices, poison_data, source):\n",
    "    res=[]\n",
    "    idxs= []\n",
    "    for ixz, item in enumerate(poison_data_predictions):\n",
    "        if np.argmax(item) == np.argmax(source):\n",
    "            res.append(poison_data[ixz])\n",
    "            idxs.append(poison_indices[ixz])\n",
    "    return np.array(res), np.array(idxs)\n",
    "\n",
    "predictions = classifier.predict(poison_data)\n",
    "\n",
    "poison_data, poison_indices = filtered_poisoned_results(predictions, poison_indices, poison_data, source)\n",
    "poison_data.shape, poison_indices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Visualize the poisoned samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poison_labels = y_train[poison_indices]\n",
    "\n",
    "fig, ax = plt.subplots(2,5, figsize=(15, 6))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, (image, label) in enumerate(zip(poison_data[:10], poison_labels[:10])):\n",
    "  with torch.no_grad():\n",
    "    logits = classifier.predict(image)\n",
    "  \n",
    "  img = np.transpose(image, (1, 2, 0))\n",
    "  ax[i].imshow(img, cmap = \"Greys\")\n",
    "  ax[i].set_title(f\"Actual Label: {label.argmax()}\\n Predicted Label {logits.argmax()}\",  fontsize=12)\n",
    "  ax[i].set_xticks([])\n",
    "  ax[i].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Save the poisoned generated sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_labels_list = []\n",
    "for i in range(len(poison_indices)):\n",
    "    poison_labels_list.append(source)\n",
    "\n",
    "poison_labels = torch.tensor(poison_labels_list)\n",
    "poison_data = torch.from_numpy(poison_data)\n",
    "\n",
    "# Save the poisoned_samples\n",
    "torch.save({'images': poison_data, 'labels': poison_labels}, f'./FL_LDP_data/poison_data.pt')\n",
    "\n",
    "# stack the poisoned_data to the training data. \n",
    "poison_x = torch.concatenate([x_train, poison_data], axis = 0)\n",
    "poison_y = torch.concatenate([y_train, poison_labels], axis = 0)\n",
    "# Save the poisoned training data\n",
    "torch.save({'images': poison_x, 'labels': poison_y}, f'./FL_LDP_data/poison_training_data.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Load the saved poisoned generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()\n",
    "\n",
    "# poison_extracted_data = torch.load('./FL_LDP_data/poison_data.pt')\n",
    "# poison_data = poison_extracted_data['images']\n",
    "# poison_labels = poison_extracted_data['labels']\n",
    "\n",
    "# training_poison_data = torch.load('./FL_LDP_data/poison_training_data.pt')\n",
    "# poison_x = training_poison_data['images']\n",
    "# poison_y = training_poison_data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Evalute the train, test and poisoned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuray on the clean training data is :  100.0\n",
      "The accuray on the clean testing data is :  100.0\n",
      "The accuray on the poison data is :  100.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_logits = model(poison_x)\n",
    "prediction = torch.sum(torch.argmax(test_logits, axis = 1) == torch.argmax(poison_y, axis = 1)) / len(poison_y)\n",
    "print('The accuray on the clean training data is : ', prediction.numpy() * 100)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_logits = model(x_test)\n",
    "prediction = torch.sum(torch.argmax(test_logits, axis = 1) == torch.argmax(y_test, axis = 1)) / len(y_test)\n",
    "print('The accuray on the clean testing data is : ', prediction.numpy() * 100)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_logits = model(poison_data)\n",
    "prediction = torch.sum(torch.argmax(test_logits, axis = 1) == torch.argmax(poison_labels, axis = 1)) / len(poison_labels)\n",
    "print('The accuray on the poison data is : ', prediction.numpy() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([530, 1, 28, 28]),\n",
       " torch.Size([530, 10]),\n",
       " torch.Size([513, 1, 28, 28]),\n",
       " torch.Size([513, 10]),\n",
       " torch.Size([17, 1, 28, 28]),\n",
       " torch.Size([17, 10]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poison_x.shape, poison_y.shape, x_train.shape, y_train.shape, poison_data.shape, poison_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Client Model with Backdoor:\n",
    "\n",
    "* Train the client model on both benign and poisoned data, embedding the backdoor in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = 'user_1_weights.pth'  # Path to your saved model weights\n",
    "poison_model = mnist_fully_connected(num_classes)\n",
    "# Load the state_dict\n",
    "# state_dict = torch.load(model_path)\n",
    "# Load the modified state_dict into the model\n",
    "# poison_model.load_state_dict(strip_prefix(state_dict, prefix=\"_module.\"))\n",
    "\n",
    "# Set up the optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, poison_model.parameters()), lr=0.02, momentum=0.9, weight_decay=2e-4)\n",
    "\n",
    "# model3 = mnist_fully_connected_IN(num_classes)\n",
    "\n",
    "poison_classifier = PyTorchClassifier(\n",
    "    model=poison_model,\n",
    "    clip_values=(min_, max_),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    "    preprocessing=(mean_, std_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "Accuracy on benign test examples: 9.210526315789473%\n",
      "Accuracy on clean train examples: 8.382066276803119%\n",
      "Accuracy on poisoned trigger examples: 0.0%\n",
      "Training Epoch 1000\n",
      "Accuracy on benign test examples: 84.21052631578947%\n",
      "Accuracy on clean train examples: 92.78752436647173%\n",
      "Accuracy on poisoned trigger examples: 100.0%\n",
      "Training Epoch 2000\n",
      "Accuracy on benign test examples: 88.1578947368421%\n",
      "Accuracy on clean train examples: 93.95711500974659%\n",
      "Accuracy on poisoned trigger examples: 88.23529411764706%\n",
      "Training Epoch 3000\n",
      "Accuracy on benign test examples: 88.1578947368421%\n",
      "Accuracy on clean train examples: 93.95711500974659%\n",
      "Accuracy on poisoned trigger examples: 88.23529411764706%\n",
      "Training Epoch 4000\n",
      "Accuracy on benign test examples: 88.1578947368421%\n",
      "Accuracy on clean train examples: 93.95711500974659%\n",
      "Accuracy on poisoned trigger examples: 88.23529411764706%\n"
     ]
    }
   ],
   "source": [
    "lr_factor = .001\n",
    "lr_schedule = [5, 10, 15]\n",
    "epoch_round = 1000\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Training Epoch\", i*epoch_round)\n",
    "    \n",
    "    predictions = poison_classifier.predict(x_test)\n",
    "    accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test.numpy(), axis=1)) / len(y_test)\n",
    "    print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
    "\n",
    "    predictions = poison_classifier.predict(x_train)\n",
    "    accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_train.numpy(), axis=1)) / len(y_train)\n",
    "    print(\"Accuracy on clean train examples: {}%\".format(accuracy * 100))\n",
    "\n",
    "    predictions = poison_classifier.predict(poison_data)\n",
    "    p_accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(poison_labels, axis=1).numpy()) / len(poison_labels)\n",
    "    print(\"Accuracy on poisoned trigger examples: {}%\".format(p_accuracy * 100))\n",
    "\n",
    "    if i != 0:\n",
    "        for param_group in poison_classifier.optimizer.param_groups:\n",
    "            param_group[\"lr\"] *= lr_factor\n",
    "    poison_classifier.fit(poison_x, poison_y, epochs=epoch_round, training_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(poison_classifier.model.state_dict(), './FL_LDP_data/poisoned_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluate the Global Model:\n",
    "\n",
    "* Assess the impact of the backdoor model on the global federated model, gradually increasing the number of clients with backdoor models and measuring the effect on the overall system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper fucntions\n",
    "def fileCollections(directory, extension):\n",
    "    \"\"\"\n",
    "    List all .pt | .pth files in the given directory and its subdirectories.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory to search for .pt | .pth files.\n",
    "        extension (str): The file extension that we need the file to be listed based on that. \n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of paths to .pt|.pth files.\n",
    "    \"\"\"\n",
    "    pt_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(extension):\n",
    "                pt_files.append(os.path.join(root, file))\n",
    "    return sorted(pt_files)\n",
    "\n",
    "\n",
    "def modelWeightsCollection(directory_path, poison_weights_path, NUM_BACKDOOR):\n",
    "    extension = '.pth'\n",
    "    model_weights = []\n",
    "\n",
    "    files = fileCollections(directory_path, extension)\n",
    "    for i in range(len(files)):\n",
    "        if i < NUM_BACKDOOR:\n",
    "            model_weights.append(poison_weights_path)\n",
    "            # print(\"Poisoned_path: \", poison_weights_path)\n",
    "        else: \n",
    "            model_weights.append(files[i])\n",
    "            # print('Clean Weight Path: ', files[i])\n",
    "\n",
    "    return model_weights\n",
    "\n",
    "def modelWeightsRandomCollection(directory_path, poison_weights_path, NUM_BACKDOOR):\n",
    "    extension = '.pth'\n",
    "    model_weights = []\n",
    "\n",
    "    # List of paths to the clean models\n",
    "    files = fileCollections(directory_path, extension) \n",
    "    files = files[1:]\n",
    "    # Randomly select positions for the poisoned models\n",
    "    poison_indices = random.sample(range(len(files)), NUM_BACKDOOR)\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        if i in poison_indices:  # If the current index is in the list of poisoned indices\n",
    "            model_weights.append(poison_weights_path)  # Add poisoned model path\n",
    "        else: \n",
    "            model_weights.append(files[i])  # Add clean model path\n",
    "\n",
    "    return model_weights\n",
    "\n",
    "def client_model_collection(models_path_list):\n",
    "    client_models_list = []\n",
    "\n",
    "    for i in range(len(models_path_list)):\n",
    "        client_model = mnist_fully_connected(num_classes)\n",
    "        state_dict = torch.load(models_path_list[i])\n",
    "        state_dict = strip_prefix(state_dict, prefix=\"_module.\")\n",
    "        client_model.load_state_dict(state_dict)\n",
    "\n",
    "        client_models_list.append(client_model)\n",
    "\n",
    "    return client_models_list\n",
    "\n",
    "def agg_weights(weights):\n",
    "    with torch.no_grad():\n",
    "        weights_avg = copy.deepcopy(weights[0])\n",
    "        for k in weights_avg.keys():\n",
    "            for i in range(1, len(weights)):\n",
    "                weights_avg[k] += weights[i][k]\n",
    "            weights_avg[k] = torch.div(weights_avg[k], len(weights))\n",
    "    return weights_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Evaluate the global model without the poisoned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Model Prediction before aggregation:  tensor([4, 1, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "Server Model Prediction after aggregation:  tensor([8, 3, 8, 8, 8, 8, 3, 8, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "clients_models_path = \"./FL_LDP_data/client_model_weights/\"\n",
    "poisoned_model_path = './FL_LDP_data/poisoned_model.pth'\n",
    "models_path_list = modelWeightsRandomCollection(clients_models_path, poisoned_model_path, 0)\n",
    "\n",
    "server_model = mnist_fully_connected(num_classes)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = server_model(poison_data)\n",
    "    print('Server Model Prediction before aggregation: ',torch.argmax(logits, axis = 1))\n",
    "poison_prediction = torch.sum(torch.argmax(logits, axis = 1) == torch.argmax(poison_labels, axis = 1)) / len(poison_labels)\n",
    "# print(\"Poison Prediction: \", poison_prediction)\n",
    "\n",
    "client_models_list = client_model_collection(models_path_list)\n",
    "\n",
    "weights = []\n",
    "for i in range(len(client_models_list)):\n",
    "    weights.append(client_models_list[i].state_dict())\n",
    "\n",
    "norms = agg_weights(weights)\n",
    "for key, value in server_model.state_dict().items():\n",
    "    server_model.state_dict()[key].data.copy_(norms[key])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = server_model(poison_data)\n",
    "    print('Server Model Prediction after aggregation: ', torch.argmax(logits, axis = 1))\n",
    "poison_prediction = torch.sum(torch.argmax(logits, axis = 1) == torch.argmax(poison_labels, axis = 1)) / len(poison_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Evaluate every single model on the poisoned genereated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 5, 8, 8, 8, 8, 3, 8, 8, 3, 8, 3, 8, 9, 3, 8, 3])\n",
      "Poison Prediction:  0.5882353\n",
      "tensor([3, 3, 8, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.11764706\n",
      "tensor([3, 3, 8, 3, 2, 3, 3, 8, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.1764706\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 3, 3, 3, 3, 3, 8, 5, 3, 3, 8])\n",
      "Poison Prediction:  0.47058824\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 3, 3, 8, 3, 3, 8, 3, 8, 3])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([8, 3, 8, 8, 2, 8, 3, 8, 3, 3, 3, 3, 3, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.3529412\n",
      "tensor([3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "Poison Prediction:  0.0\n",
      "tensor([8, 3, 8, 8, 2, 8, 3, 8, 8, 2, 2, 2, 3, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.4117647\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 3, 3, 8, 3, 3, 3, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([3, 3, 8, 3, 8, 8, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.29411766\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 8, 8, 3, 8, 3, 8, 8, 3, 8, 8])\n",
      "Poison Prediction:  0.7647059\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 3, 3, 3])\n",
      "Poison Prediction:  0.0\n",
      "tensor([8, 3, 8, 8, 2, 8, 3, 8, 9, 3, 8, 3, 3, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.4117647\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 8, 3, 3, 3, 3, 3, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.47058824\n",
      "tensor([8, 5, 2, 8, 8, 8, 3, 8, 8, 8, 2, 5, 2, 9, 3, 3, 8])\n",
      "Poison Prediction:  0.47058824\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 8, 5, 3, 3, 8, 9, 3, 3, 8])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 8, 8, 3, 3, 3, 8, 8, 3, 8, 2])\n",
      "Poison Prediction:  0.64705884\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 8, 8, 3, 8, 5, 8, 8, 3, 8, 5])\n",
      "Poison Prediction:  0.7058824\n",
      "tensor([3, 8, 8, 3, 8, 8, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.29411766\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.4117647\n",
      "tensor([1, 3, 1, 8, 2, 8, 3, 3, 3, 3, 3, 3, 8, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.23529412\n",
      "tensor([8, 3, 8, 8, 2, 8, 3, 8, 3, 3, 3, 3, 3, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.3529412\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 8, 3, 8, 3, 3, 8, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.5882353\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 8, 5, 3, 3, 3, 3, 9, 3, 3, 3])\n",
      "Poison Prediction:  0.05882353\n",
      "tensor([3, 8, 8, 3, 3, 8, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.23529412\n",
      "tensor([3, 8, 8, 8, 3, 8, 3, 8, 3, 5, 3, 3, 8, 8, 3, 3, 5])\n",
      "Poison Prediction:  0.4117647\n",
      "tensor([8, 3, 8, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5])\n",
      "Poison Prediction:  0.11764706\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 3, 3, 8, 5, 5, 5, 8])\n",
      "Poison Prediction:  0.64705884\n",
      "tensor([3, 3, 2, 8, 2, 8, 3, 3, 3, 3, 3, 3, 3, 9, 3, 3, 2])\n",
      "Poison Prediction:  0.11764706\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 8, 8, 3, 3, 3, 3, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.4117647\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.3529412\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 3, 3, 3, 3, 8, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([3, 3, 8, 8, 2, 3, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.1764706\n",
      "tensor([3, 3, 8, 8, 2, 8, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.23529412\n",
      "tensor([8, 3, 8, 3, 2, 8, 3, 3, 3, 3, 3, 5, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.23529412\n",
      "tensor([8, 5, 8, 8, 8, 8, 8, 8, 8, 5, 8, 3, 3, 8, 5, 8, 5])\n",
      "Poison Prediction:  0.64705884\n",
      "tensor([3, 3, 8, 3, 3, 8, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3])\n",
      "Poison Prediction:  0.11764706\n",
      "tensor([8, 3, 8, 8, 2, 8, 3, 8, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.3529412\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 3, 3, 3, 3, 8, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.47058824\n",
      "tensor([8, 8, 8, 8, 2, 8, 3, 8, 8, 3, 3, 3, 8, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.5882353\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 8, 8, 3, 3, 3, 8, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.64705884\n",
      "tensor([1, 8, 8, 8, 8, 8, 3, 8, 8, 3, 3, 3, 2, 8, 3, 8, 3])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([3, 3, 8, 8, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "Poison Prediction:  0.11764706\n",
      "tensor([3, 3, 8, 3, 8, 8, 3, 8, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.29411766\n",
      "tensor([3, 3, 8, 3, 2, 3, 3, 8, 3, 3, 3, 3, 3, 5, 3, 3, 3])\n",
      "Poison Prediction:  0.11764706\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 8, 3, 3, 3, 8, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 3, 3, 3, 3, 8, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.47058824\n",
      "tensor([8, 8, 8, 8, 2, 8, 3, 8, 8, 3, 8, 3, 8, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.64705884\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 8, 8, 3, 8, 3, 8, 8, 3, 8, 8])\n",
      "Poison Prediction:  0.7647059\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 8, 3, 3, 3, 3, 8, 3, 5, 3])\n",
      "Poison Prediction:  0.47058824\n",
      "tensor([8, 3, 8, 3, 8, 8, 3, 3, 5, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.29411766\n",
      "tensor([8, 5, 8, 8, 8, 8, 8, 8, 8, 8, 3, 5, 8, 8, 8, 8, 8])\n",
      "Poison Prediction:  0.8235294\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 3, 8, 3, 3, 3, 3, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.4117647\n",
      "tensor([3, 3, 8, 8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.1764706\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 3, 3, 3, 3, 8, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 8, 8, 8, 8, 3, 8, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.7647059\n",
      "tensor([3, 8, 8, 3, 2, 8, 3, 3, 3, 3, 3, 3, 3, 9, 3, 3, 3])\n",
      "Poison Prediction:  0.1764706\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.47058824\n",
      "tensor([3, 3, 8, 8, 2, 8, 3, 8, 8, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.3529412\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 8, 3, 5, 3, 3, 8, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.5882353\n",
      "tensor([3, 3, 8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 3, 3, 3])\n",
      "Poison Prediction:  0.05882353\n",
      "tensor([8, 5, 8, 8, 8, 8, 3, 3, 3, 5, 3, 3, 3, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.4117647\n",
      "tensor([3, 3, 8, 8, 3, 8, 3, 8, 8, 3, 8, 3, 3, 8, 3, 8, 8])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([3, 3, 8, 8, 8, 3, 3, 8, 3, 3, 3, 3, 3, 9, 3, 3, 3])\n",
      "Poison Prediction:  0.23529412\n",
      "tensor([8, 3, 8, 8, 3, 8, 3, 8, 8, 3, 3, 3, 3, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.47058824\n",
      "tensor([8, 5, 8, 8, 8, 8, 3, 8, 8, 5, 3, 3, 3, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 8, 8, 8, 3, 3, 8, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.7058824\n",
      "tensor([3, 3, 8, 3, 8, 8, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.23529412\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 3, 3, 3, 3, 8, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([2, 3, 2, 3, 2, 8, 3, 3, 3, 3, 2, 3, 3, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.11764706\n",
      "tensor([3, 3, 8, 8, 8, 8, 3, 8, 8, 3, 8, 3, 3, 8, 3, 8, 8])\n",
      "Poison Prediction:  0.5882353\n",
      "tensor([3, 3, 8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.11764706\n",
      "tensor([3, 3, 8, 8, 2, 8, 3, 8, 8, 3, 3, 3, 3, 8, 3, 3, 5])\n",
      "Poison Prediction:  0.3529412\n",
      "tensor([8, 5, 8, 8, 8, 8, 3, 8, 8, 3, 3, 3, 3, 8, 3, 3, 5])\n",
      "Poison Prediction:  0.47058824\n",
      "tensor([3, 3, 2, 3, 8, 8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2])\n",
      "Poison Prediction:  0.11764706\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 3, 3, 3, 3, 3, 8, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([8, 3, 8, 8, 2, 8, 3, 3, 3, 8, 8, 3, 3, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.47058824\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 3, 3, 8, 3, 8, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.5882353\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 8, 8, 3, 8, 3, 8, 8, 3, 8, 8])\n",
      "Poison Prediction:  0.7647059\n",
      "tensor([3, 3, 8, 8, 8, 8, 3, 3, 8, 3, 3, 3, 3, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.4117647\n",
      "tensor([3, 3, 8, 3, 8, 8, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.23529412\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 8, 3, 8, 3, 3, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.5882353\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 3, 3, 8, 3, 3, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 8, 3, 3, 3, 3, 8, 3, 8, 2])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([8, 5, 8, 8, 8, 8, 3, 8, 3, 5, 3, 3, 3, 9, 3, 3, 2])\n",
      "Poison Prediction:  0.3529412\n",
      "tensor([8, 8, 8, 8, 8, 8, 3, 3, 8, 8, 3, 3, 8, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.5882353\n",
      "tensor([8, 5, 2, 8, 2, 8, 3, 8, 2, 5, 2, 2, 3, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.29411766\n",
      "tensor([3, 3, 2, 3, 2, 8, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.11764706\n",
      "tensor([3, 8, 8, 3, 8, 8, 3, 8, 8, 8, 3, 3, 3, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 8, 3, 3, 3, 8, 8, 3, 3, 2])\n",
      "Poison Prediction:  0.5294118\n",
      "tensor([3, 8, 8, 8, 2, 8, 3, 8, 8, 8, 3, 3, 3, 8, 3, 8, 8])\n",
      "Poison Prediction:  0.5882353\n",
      "tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 8, 3, 3, 8, 3, 8, 8])\n",
      "Poison Prediction:  0.7647059\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.3529412\n",
      "tensor([8, 8, 8, 8, 2, 8, 3, 8, 8, 8, 8, 3, 8, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.7058824\n",
      "tensor([3, 3, 8, 8, 8, 3, 3, 3, 8, 3, 3, 3, 3, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.3529412\n",
      "tensor([8, 5, 8, 8, 8, 8, 8, 8, 3, 5, 3, 3, 8, 8, 3, 3, 8])\n",
      "Poison Prediction:  0.5882353\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 3, 3, 3, 3, 8, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.47058824\n",
      "tensor([8, 3, 8, 8, 8, 8, 3, 8, 3, 3, 8, 3, 8, 8, 3, 3, 3])\n",
      "Poison Prediction:  0.5294118\n"
     ]
    }
   ],
   "source": [
    "for model in client_models_list:\n",
    "    with torch.no_grad():\n",
    "        logits = model(poison_data)\n",
    "        print(torch.argmax(logits, axis = 1))\n",
    "        # print(torch.argmax(poison_labels, axis = 1))\n",
    "    poison_prediction = torch.sum(torch.argmax(logits, axis = 1) == torch.argmax(poison_labels, axis = 1)) / len(poison_labels)\n",
    "    print(\"Poison Prediction: \", poison_prediction.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Check the global model by adding model with backdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for round in range(0, 100):\n",
    "    # print(round)\n",
    "    clients_models_path = \"./FL_LDP_data/client_model_weights/\"\n",
    "    poisoned_model_path = './FL_LDP_data/poisoned_model.pth'\n",
    "    models_path_list = modelWeightsRandomCollection(clients_models_path, poisoned_model_path, round)\n",
    "    client_models_list = client_model_collection(models_path_list)\n",
    "\n",
    "    \n",
    "    server_model = mnist_fully_connected(num_classes)\n",
    "\n",
    "    weights = []\n",
    "    for i in range(len(client_models_list)):\n",
    "        weights.append(client_models_list[i].state_dict())\n",
    "\n",
    "    norms = agg_weights(weights)\n",
    "\n",
    "    for key, value in server_model.state_dict().items():\n",
    "        if 'norm' not in key and 'bn' not in key and 'downsample.1' not in key:\n",
    "            server_model.state_dict()[key].data.copy_(norms[key])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = server_model(x_test)\n",
    "    test_prediction = torch.sum(torch.argmax(logits, axis = 1) == torch.argmax(y_test, axis = 1)) / len(y_test)\n",
    "    # print('Test Prediction Result: ', test_prediction)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = server_model(poison_x)\n",
    "    train_prediction = torch.sum(torch.argmax(logits, axis = 1) == torch.argmax(poison_y, axis = 1)) / len(poison_y)\n",
    "    # print('Train Prediction Result: ', train_prediction)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = server_model(poison_data)\n",
    "    poison_prediction = torch.sum(torch.argmax(logits, axis = 1) == torch.argmax(poison_labels, axis = 1)) / len(poison_labels)\n",
    "    # print(\"Poison Prediction: \", poison_prediction)\n",
    "\n",
    "    # print('Poison Predictoin Result: ', poison_prediction)\n",
    "    result.append([test_prediction.numpy(), train_prediction.numpy(), poison_prediction.numpy(), round, 100-round]) \n",
    "\n",
    "    # print(models_path_list)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['Test Data Accuracy', 'Train Data Accuracy', 'Poison Data Accuracy', 'Poison Model', 'Clean Model']\n",
    "# Extract columns from the data\n",
    "test_acc = [float(row[0]) for row in result]\n",
    "train_acc = [float(row[1]) for row in result]\n",
    "poison_acc = [float(row[2]) for row in result]\n",
    "pois_num = [row[3] for row in result]  # x-axis, index values\n",
    "clean_num = [row[4] for row in result]  # another variable\n",
    "\n",
    "# Plot each column as a separate line\n",
    "plt.plot(pois_num, test_acc, label=\"Test Accuracy\")\n",
    "plt.plot(pois_num, train_acc, label=\"Train Accuracy\")\n",
    "plt.plot(pois_num, poison_acc, label=\"Poison Accuracy\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Poison Client Models\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Avg. Model Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privatefl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
